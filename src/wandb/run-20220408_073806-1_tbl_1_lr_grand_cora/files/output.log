[INFO] Experiment mode is :  ON
[INFO] ODE function :  laplacian
[INFO] Block type :  attention
[INFO] T value :  128.0
[INFO] L1 regularization on :  False
[INFO] L1 reg coefficient :  0.001
/home/administrator/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py:11: UserWarning: Dopri5Solver: Unexpected arguments {'step_size': 1}
  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))
GNNEarly
m1.module.weight
torch.Size([80, 1433])
m1.module.bias
torch.Size([80])
m2.module.weight
torch.Size([7, 80])
m2.module.bias
torch.Size([7])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
odeblock.multihead_att_layer.Q.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.Q.bias
torch.Size([128])
odeblock.multihead_att_layer.V.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.V.bias
torch.Size([128])
odeblock.multihead_att_layer.K.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.K.bias
torch.Size([128])
odeblock.multihead_att_layer.Wout.weight
torch.Size([80, 16])
odeblock.multihead_att_layer.Wout.bias
torch.Size([80])
/home/administrator/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py:11: UserWarning: EarlyStopDopri5: Unexpected arguments {'step_size': 1}
  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))
Epoch: 001, Runtime 0.884571, Loss 1.949502, forward nfe 242, backward nfe 0, Train: 0.1429, Val: 0.3103, Test: 0.2883, Best time: 70.1866
Epoch: 002, Runtime 0.846206, Loss 2.111881, forward nfe 1098, backward nfe 0, Train: 0.1429, Val: 0.3103, Test: 0.2883, Best time: 128.0000
Epoch: 003, Runtime 0.855559, Loss 1.989634, forward nfe 1960, backward nfe 0, Train: 0.1429, Val: 0.3103, Test: 0.2883, Best time: 128.0000
Epoch: 004, Runtime 0.878063, Loss 1.995111, forward nfe 2828, backward nfe 0, Train: 0.1429, Val: 0.3103, Test: 0.2883, Best time: 128.0000
Epoch: 005, Runtime 1.001952, Loss 1.929029, forward nfe 3684, backward nfe 0, Train: 0.1429, Val: 0.3103, Test: 0.2883, Best time: 128.0000
Epoch: 006, Runtime 0.862395, Loss 1.912687, forward nfe 4546, backward nfe 0, Train: 0.1429, Val: 0.3103, Test: 0.2883, Best time: 128.0000
Epoch: 007, Runtime 0.865177, Loss 1.914197, forward nfe 5408, backward nfe 0, Train: 0.4857, Val: 0.3882, Test: 0.3909, Best time: 2.7617
Epoch: 008, Runtime 0.884873, Loss 1.898682, forward nfe 6270, backward nfe 0, Train: 0.4857, Val: 0.4132, Test: 0.4102, Best time: 2.0964
Epoch: 009, Runtime 0.878910, Loss 1.876460, forward nfe 7132, backward nfe 0, Train: 0.5286, Val: 0.4721, Test: 0.4954, Best time: 3.1942
Epoch: 010, Runtime 1.003103, Loss 1.843802, forward nfe 7994, backward nfe 0, Train: 0.5429, Val: 0.4919, Test: 0.5168, Best time: 3.2709
Epoch: 011, Runtime 0.877447, Loss 1.810017, forward nfe 8856, backward nfe 0, Train: 0.5357, Val: 0.4941, Test: 0.5360, Best time: 1.8342
Epoch: 012, Runtime 0.839205, Loss 1.770813, forward nfe 9706, backward nfe 0, Train: 0.6071, Val: 0.5581, Test: 0.5990, Best time: 3.4178
Epoch: 013, Runtime 0.847366, Loss 1.699261, forward nfe 10556, backward nfe 0, Train: 0.6857, Val: 0.6419, Test: 0.6711, Best time: 17.3010
Epoch: 014, Runtime 0.840601, Loss 1.621985, forward nfe 11412, backward nfe 0, Train: 0.7071, Val: 0.6596, Test: 0.6802, Best time: 55.3364
Epoch: 015, Runtime 0.871802, Loss 1.544872, forward nfe 12268, backward nfe 0, Train: 0.7286, Val: 0.6787, Test: 0.7107, Best time: 112.0574
Epoch: 016, Runtime 0.857429, Loss 1.472812, forward nfe 13118, backward nfe 0, Train: 0.7571, Val: 0.6963, Test: 0.7208, Best time: 107.8667
Epoch: 017, Runtime 0.829035, Loss 1.347540, forward nfe 13968, backward nfe 0, Train: 0.7571, Val: 0.6963, Test: 0.7208, Best time: 128.0000
Epoch: 018, Runtime 0.857728, Loss 1.270719, forward nfe 14818, backward nfe 0, Train: 0.7929, Val: 0.7213, Test: 0.7482, Best time: 90.3484
Epoch: 019, Runtime 0.861640, Loss 1.143000, forward nfe 15674, backward nfe 0, Train: 0.7857, Val: 0.7478, Test: 0.7726, Best time: 77.0702
Epoch: 020, Runtime 0.849892, Loss 1.077217, forward nfe 16512, backward nfe 0, Train: 0.7857, Val: 0.7478, Test: 0.7726, Best time: 128.0000
Epoch: 021, Runtime 0.823695, Loss 1.059355, forward nfe 17362, backward nfe 0, Train: 0.7857, Val: 0.7581, Test: 0.7827, Best time: 130.1081
Epoch: 022, Runtime 0.811860, Loss 0.923656, forward nfe 18200, backward nfe 0, Train: 0.7857, Val: 0.7581, Test: 0.7827, Best time: 128.0000
Epoch: 023, Runtime 0.819907, Loss 0.887695, forward nfe 19038, backward nfe 0, Train: 0.8071, Val: 0.7691, Test: 0.7868, Best time: 83.5157
Epoch: 024, Runtime 0.846509, Loss 0.856451, forward nfe 19864, backward nfe 0, Train: 0.8071, Val: 0.7691, Test: 0.7868, Best time: 128.0000
Epoch: 025, Runtime 0.847999, Loss 0.855335, forward nfe 20702, backward nfe 0, Train: 0.8071, Val: 0.7691, Test: 0.7868, Best time: 128.0000
Epoch: 026, Runtime 0.827809, Loss 0.818189, forward nfe 21528, backward nfe 0, Train: 0.8071, Val: 0.7691, Test: 0.7868, Best time: 128.0000
Epoch: 027, Runtime 0.801781, Loss 0.833040, forward nfe 22354, backward nfe 0, Train: 0.7929, Val: 0.7853, Test: 0.8030, Best time: 133.6131
Epoch: 028, Runtime 0.822384, Loss 0.727215, forward nfe 23180, backward nfe 0, Train: 0.7929, Val: 0.7853, Test: 0.8030, Best time: 128.0000
Epoch: 029, Runtime 0.814532, Loss 0.785689, forward nfe 23994, backward nfe 0, Train: 0.7929, Val: 0.7853, Test: 0.8030, Best time: 128.0000
Epoch: 030, Runtime 0.813332, Loss 0.722580, forward nfe 24802, backward nfe 0, Train: 0.7929, Val: 0.7853, Test: 0.8030, Best time: 128.0000
Epoch: 031, Runtime 0.802900, Loss 0.715568, forward nfe 25610, backward nfe 0, Train: 0.7929, Val: 0.7853, Test: 0.8030, Best time: 128.0000
Epoch: 032, Runtime 0.809222, Loss 0.708007, forward nfe 26412, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 134.2859
Epoch: 033, Runtime 0.795922, Loss 0.712754, forward nfe 27214, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 034, Runtime 0.792990, Loss 0.734043, forward nfe 28010, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 035, Runtime 0.779441, Loss 0.680297, forward nfe 28794, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 036, Runtime 0.764710, Loss 0.706028, forward nfe 29560, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 037, Runtime 0.766701, Loss 0.696633, forward nfe 30326, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 038, Runtime 0.758627, Loss 0.686931, forward nfe 31086, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 039, Runtime 0.712759, Loss 0.721193, forward nfe 31822, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 040, Runtime 0.720444, Loss 0.639378, forward nfe 32558, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 041, Runtime 0.707991, Loss 0.679808, forward nfe 33294, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 042, Runtime 0.714672, Loss 0.674926, forward nfe 34024, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 043, Runtime 0.706921, Loss 0.694297, forward nfe 34754, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 044, Runtime 0.683206, Loss 0.675998, forward nfe 35466, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 045, Runtime 0.691384, Loss 0.751237, forward nfe 36166, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 046, Runtime 0.681684, Loss 0.657974, forward nfe 36866, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 047, Runtime 0.675291, Loss 0.614040, forward nfe 37560, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 048, Runtime 0.669997, Loss 0.617153, forward nfe 38254, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 049, Runtime 0.655443, Loss 0.638140, forward nfe 38936, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 050, Runtime 0.660282, Loss 0.587885, forward nfe 39612, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 051, Runtime 0.660505, Loss 0.641731, forward nfe 40294, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 052, Runtime 0.652310, Loss 0.602131, forward nfe 40964, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 053, Runtime 0.641069, Loss 0.586852, forward nfe 41634, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 054, Runtime 0.646035, Loss 0.624070, forward nfe 42292, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 055, Runtime 0.635983, Loss 0.537557, forward nfe 42944, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 056, Runtime 0.642028, Loss 0.586583, forward nfe 43602, backward nfe 0, Train: 0.7786, Val: 0.8074, Test: 0.8244, Best time: 128.0000
Epoch: 057, Runtime 0.650704, Loss 0.559176, forward nfe 44254, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8254, Best time: 218.1323
Epoch: 058, Runtime 0.653130, Loss 0.569718, forward nfe 44894, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8254, Best time: 128.0000
Epoch: 059, Runtime 0.812792, Loss 0.567793, forward nfe 45534, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8254, Best time: 128.0000
Epoch: 060, Runtime 0.609671, Loss 0.554568, forward nfe 46168, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8254, Best time: 128.0000
Epoch: 061, Runtime 0.609558, Loss 0.569002, forward nfe 46790, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 123.3850
Epoch: 062, Runtime 0.600424, Loss 0.586727, forward nfe 47406, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 063, Runtime 0.615476, Loss 0.538670, forward nfe 48016, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 064, Runtime 0.627520, Loss 0.513061, forward nfe 48632, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 065, Runtime 0.605843, Loss 0.498073, forward nfe 49248, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 066, Runtime 0.603209, Loss 0.537440, forward nfe 49846, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 067, Runtime 0.612825, Loss 0.513697, forward nfe 50444, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 068, Runtime 0.598216, Loss 0.596663, forward nfe 51042, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 069, Runtime 0.594599, Loss 0.597690, forward nfe 51634, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 070, Runtime 0.597707, Loss 0.518605, forward nfe 52220, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 071, Runtime 0.584529, Loss 0.641662, forward nfe 52806, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 072, Runtime 0.575794, Loss 0.534962, forward nfe 53386, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 073, Runtime 0.571237, Loss 0.559096, forward nfe 53954, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 074, Runtime 0.572167, Loss 0.610518, forward nfe 54516, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 075, Runtime 0.574460, Loss 0.566755, forward nfe 55078, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 076, Runtime 0.566543, Loss 0.521433, forward nfe 55640, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 077, Runtime 0.570781, Loss 0.483259, forward nfe 56196, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 078, Runtime 0.541506, Loss 0.460721, forward nfe 56740, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 079, Runtime 0.541119, Loss 0.461419, forward nfe 57272, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 080, Runtime 0.537083, Loss 0.445972, forward nfe 57804, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 081, Runtime 0.547944, Loss 0.400631, forward nfe 58330, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 082, Runtime 0.533876, Loss 0.530471, forward nfe 58856, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 083, Runtime 0.525962, Loss 0.416328, forward nfe 59376, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 084, Runtime 0.531364, Loss 0.471124, forward nfe 59884, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 085, Runtime 0.521789, Loss 0.414864, forward nfe 60398, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 086, Runtime 0.508066, Loss 0.445847, forward nfe 60900, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 087, Runtime 0.506612, Loss 0.433822, forward nfe 61396, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 088, Runtime 0.508072, Loss 0.495866, forward nfe 61892, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 089, Runtime 0.503826, Loss 0.469848, forward nfe 62388, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 090, Runtime 0.526955, Loss 0.477292, forward nfe 62878, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 091, Runtime 0.500159, Loss 0.378947, forward nfe 63362, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 092, Runtime 0.668220, Loss 0.515383, forward nfe 63846, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 093, Runtime 0.487032, Loss 0.361115, forward nfe 64324, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 094, Runtime 0.482874, Loss 0.416933, forward nfe 64802, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 095, Runtime 0.486714, Loss 0.412885, forward nfe 65274, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Traceback (most recent call last):
  File "test_multiple_planetoid_splits.py", line 387, in <module>
    fw_nfes, losses, train_accs, val_accs, test_accs = main(opt)
  File "/home/administrator/hieu/graph-neural-pde/src/run_GNN.py", line 297, in main
    return fw_nfes, losses, train_accs, val_accs, test_accs
NameError: name 'fw_nfes' is not defined
Epoch: 096, Runtime 0.468555, Loss 0.451527, forward nfe 65734, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 097, Runtime 0.490517, Loss 0.354310, forward nfe 66206, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 098, Runtime 0.469512, Loss 0.417661, forward nfe 66660, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
Epoch: 099, Runtime 0.474103, Loss 0.451493, forward nfe 67108, backward nfe 0, Train: 0.8714, Val: 0.8206, Test: 0.8315, Best time: 128.0000
