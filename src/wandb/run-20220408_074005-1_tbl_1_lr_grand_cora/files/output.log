[INFO] Experiment mode is :  ON
[INFO] ODE function :  laplacian
[INFO] Block type :  attention
[INFO] T value :  128.0
[INFO] L1 regularization on :  False
[INFO] L1 reg coefficient :  0.001
/home/administrator/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py:11: UserWarning: Dopri5Solver: Unexpected arguments {'step_size': 1}
  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))
/home/administrator/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py:11: UserWarning: EarlyStopDopri5: Unexpected arguments {'step_size': 1}
  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))
GNNEarly
m1.module.weight
torch.Size([80, 1433])
m1.module.bias
torch.Size([80])
m2.module.weight
torch.Size([7, 80])
m2.module.bias
torch.Size([7])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
odeblock.multihead_att_layer.Q.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.Q.bias
torch.Size([128])
odeblock.multihead_att_layer.V.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.V.bias
torch.Size([128])
odeblock.multihead_att_layer.K.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.K.bias
torch.Size([128])
odeblock.multihead_att_layer.Wout.weight
torch.Size([80, 16])
odeblock.multihead_att_layer.Wout.bias
torch.Size([80])
Epoch: 001, Runtime 0.911769, Loss 1.949119, forward nfe 242, backward nfe 0, Train: 0.2429, Val: 0.2456, Test: 0.2254, Best time: 0.0948
Epoch: 002, Runtime 0.860795, Loss 2.061026, forward nfe 1092, backward nfe 0, Train: 0.2429, Val: 0.2456, Test: 0.2254, Best time: 128.0000
Epoch: 003, Runtime 0.875922, Loss 1.984920, forward nfe 1948, backward nfe 0, Train: 0.2429, Val: 0.2456, Test: 0.2254, Best time: 128.0000
Epoch: 004, Runtime 0.894665, Loss 1.931863, forward nfe 2810, backward nfe 0, Train: 0.2429, Val: 0.2456, Test: 0.2254, Best time: 128.0000
Epoch: 005, Runtime 0.890946, Loss 1.893537, forward nfe 3672, backward nfe 0, Train: 0.3643, Val: 0.3015, Test: 0.2944, Best time: 0.8606
Epoch: 006, Runtime 0.893876, Loss 1.855464, forward nfe 4528, backward nfe 0, Train: 0.3643, Val: 0.4015, Test: 0.3797, Best time: 25.7018
Epoch: 007, Runtime 1.054221, Loss 1.785233, forward nfe 5378, backward nfe 0, Train: 0.4714, Val: 0.5199, Test: 0.4934, Best time: 20.2851
Epoch: 008, Runtime 0.843258, Loss 1.711639, forward nfe 6228, backward nfe 0, Train: 0.6143, Val: 0.6801, Test: 0.6660, Best time: 58.9077
Epoch: 009, Runtime 0.844314, Loss 1.611044, forward nfe 7078, backward nfe 0, Train: 0.6071, Val: 0.6956, Test: 0.6822, Best time: 12.1119
Epoch: 010, Runtime 0.976116, Loss 1.503142, forward nfe 7928, backward nfe 0, Train: 0.6857, Val: 0.7794, Test: 0.7584, Best time: 33.5176
Epoch: 011, Runtime 0.870148, Loss 1.391092, forward nfe 8778, backward nfe 0, Train: 0.6857, Val: 0.7794, Test: 0.7584, Best time: 128.0000
Epoch: 012, Runtime 0.881352, Loss 1.288255, forward nfe 9622, backward nfe 0, Train: 0.6857, Val: 0.7794, Test: 0.7584, Best time: 128.0000
Epoch: 013, Runtime 0.865968, Loss 1.263657, forward nfe 10466, backward nfe 0, Train: 0.6857, Val: 0.7794, Test: 0.7584, Best time: 128.0000
Epoch: 014, Runtime 0.864069, Loss 1.195560, forward nfe 11310, backward nfe 0, Train: 0.6857, Val: 0.7794, Test: 0.7584, Best time: 128.0000
Epoch: 015, Runtime 0.857682, Loss 1.173975, forward nfe 12148, backward nfe 0, Train: 0.6857, Val: 0.7794, Test: 0.7584, Best time: 128.0000
Epoch: 016, Runtime 0.861698, Loss 1.129992, forward nfe 12986, backward nfe 0, Train: 0.6857, Val: 0.7794, Test: 0.7584, Best time: 128.0000
Epoch: 017, Runtime 0.863853, Loss 1.247639, forward nfe 13824, backward nfe 0, Train: 0.7571, Val: 0.7824, Test: 0.7655, Best time: 37.4703
Epoch: 018, Runtime 0.850748, Loss 1.062256, forward nfe 14656, backward nfe 0, Train: 0.7571, Val: 0.7824, Test: 0.7655, Best time: 128.0000
Epoch: 019, Runtime 0.845905, Loss 1.103380, forward nfe 15488, backward nfe 0, Train: 0.7571, Val: 0.7824, Test: 0.7655, Best time: 128.0000
Epoch: 020, Runtime 0.851110, Loss 1.062842, forward nfe 16320, backward nfe 0, Train: 0.7571, Val: 0.7824, Test: 0.7655, Best time: 128.0000
Epoch: 021, Runtime 0.848932, Loss 1.022310, forward nfe 17146, backward nfe 0, Train: 0.7571, Val: 0.7824, Test: 0.7655, Best time: 128.0000
Epoch: 022, Runtime 0.846691, Loss 1.041010, forward nfe 17972, backward nfe 0, Train: 0.7571, Val: 0.7824, Test: 0.7655, Best time: 128.0000
Epoch: 023, Runtime 0.830357, Loss 1.009955, forward nfe 18798, backward nfe 0, Train: 0.7500, Val: 0.8015, Test: 0.7807, Best time: 24.5058
Epoch: 024, Runtime 0.832167, Loss 0.946181, forward nfe 19618, backward nfe 0, Train: 0.7500, Val: 0.8015, Test: 0.7807, Best time: 128.0000
Epoch: 025, Runtime 0.827351, Loss 0.909225, forward nfe 20426, backward nfe 0, Train: 0.7500, Val: 0.8015, Test: 0.7807, Best time: 128.0000
Epoch: 026, Runtime 0.806758, Loss 1.010003, forward nfe 21228, backward nfe 0, Train: 0.7500, Val: 0.8015, Test: 0.7807, Best time: 128.0000
Epoch: 027, Runtime 0.806409, Loss 1.099154, forward nfe 22024, backward nfe 0, Train: 0.7500, Val: 0.8015, Test: 0.7807, Best time: 128.0000
Epoch: 028, Runtime 0.794762, Loss 0.958481, forward nfe 22820, backward nfe 0, Train: 0.7500, Val: 0.8015, Test: 0.7807, Best time: 128.0000
Epoch: 029, Runtime 0.795631, Loss 1.352194, forward nfe 23598, backward nfe 0, Train: 0.7500, Val: 0.8015, Test: 0.7807, Best time: 128.0000
Epoch: 030, Runtime 0.790388, Loss 1.052820, forward nfe 24376, backward nfe 0, Train: 0.7500, Val: 0.8015, Test: 0.7807, Best time: 128.0000
Epoch: 031, Runtime 0.776747, Loss 1.034521, forward nfe 25142, backward nfe 0, Train: 0.7500, Val: 0.8015, Test: 0.7807, Best time: 128.0000
Epoch: 032, Runtime 0.786916, Loss 1.145989, forward nfe 25908, backward nfe 0, Train: 0.7500, Val: 0.8015, Test: 0.7807, Best time: 128.0000
Epoch: 033, Runtime 0.769665, Loss 1.109882, forward nfe 26674, backward nfe 0, Train: 0.7500, Val: 0.8015, Test: 0.7807, Best time: 128.0000
Epoch: 034, Runtime 0.777972, Loss 0.983165, forward nfe 27428, backward nfe 0, Train: 0.8286, Val: 0.8081, Test: 0.7858, Best time: 38.9732
Epoch: 035, Runtime 0.762173, Loss 0.898212, forward nfe 28188, backward nfe 0, Train: 0.8286, Val: 0.8081, Test: 0.7858, Best time: 128.0000
Epoch: 036, Runtime 0.759306, Loss 1.009268, forward nfe 28936, backward nfe 0, Train: 0.8286, Val: 0.8081, Test: 0.7858, Best time: 128.0000
Epoch: 037, Runtime 0.760706, Loss 0.962399, forward nfe 29678, backward nfe 0, Train: 0.8286, Val: 0.8081, Test: 0.7858, Best time: 128.0000
Epoch: 038, Runtime 0.750426, Loss 0.825863, forward nfe 30420, backward nfe 0, Train: 0.8286, Val: 0.8081, Test: 0.7858, Best time: 128.0000
Epoch: 039, Runtime 0.748749, Loss 0.881266, forward nfe 31162, backward nfe 0, Train: 0.8286, Val: 0.8081, Test: 0.7858, Best time: 128.0000
Epoch: 040, Runtime 0.748964, Loss 0.877680, forward nfe 31892, backward nfe 0, Train: 0.8286, Val: 0.8081, Test: 0.7858, Best time: 128.0000
Epoch: 041, Runtime 0.732973, Loss 0.831773, forward nfe 32616, backward nfe 0, Train: 0.8286, Val: 0.8081, Test: 0.7858, Best time: 128.0000
Epoch: 042, Runtime 0.728067, Loss 0.888267, forward nfe 33328, backward nfe 0, Train: 0.8286, Val: 0.8081, Test: 0.7858, Best time: 128.0000
Epoch: 043, Runtime 0.734428, Loss 0.882672, forward nfe 34040, backward nfe 0, Train: 0.8143, Val: 0.8191, Test: 0.7868, Best time: 71.9222
Epoch: 044, Runtime 0.725516, Loss 0.801227, forward nfe 34746, backward nfe 0, Train: 0.8143, Val: 0.8191, Test: 0.7868, Best time: 128.0000
Epoch: 045, Runtime 0.719406, Loss 0.812561, forward nfe 35446, backward nfe 0, Train: 0.8143, Val: 0.8191, Test: 0.7868, Best time: 128.0000
Epoch: 046, Runtime 0.712297, Loss 0.843553, forward nfe 36146, backward nfe 0, Train: 0.8143, Val: 0.8191, Test: 0.7868, Best time: 128.0000
Epoch: 047, Runtime 0.708058, Loss 0.838769, forward nfe 36840, backward nfe 0, Train: 0.8143, Val: 0.8191, Test: 0.7868, Best time: 128.0000
Epoch: 048, Runtime 0.710013, Loss 0.769420, forward nfe 37534, backward nfe 0, Train: 0.8143, Val: 0.8191, Test: 0.7868, Best time: 128.0000
Epoch: 049, Runtime 0.706697, Loss 0.819855, forward nfe 38222, backward nfe 0, Train: 0.8143, Val: 0.8191, Test: 0.7868, Best time: 128.0000
Epoch: 050, Runtime 0.685380, Loss 0.745712, forward nfe 38910, backward nfe 0, Train: 0.8143, Val: 0.8191, Test: 0.7868, Best time: 128.0000
Epoch: 051, Runtime 0.697960, Loss 0.817481, forward nfe 39580, backward nfe 0, Train: 0.8143, Val: 0.8191, Test: 0.7868, Best time: 128.0000
Epoch: 052, Runtime 0.686321, Loss 0.744596, forward nfe 40262, backward nfe 0, Train: 0.8143, Val: 0.8191, Test: 0.7868, Best time: 128.0000
Epoch: 053, Runtime 0.695023, Loss 0.841029, forward nfe 40938, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 66.5029
Epoch: 054, Runtime 0.691272, Loss 0.782734, forward nfe 41608, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 055, Runtime 0.669763, Loss 0.826499, forward nfe 42272, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 056, Runtime 0.672191, Loss 0.764692, forward nfe 42930, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 057, Runtime 0.664804, Loss 0.721828, forward nfe 43588, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 058, Runtime 0.665398, Loss 0.872497, forward nfe 44234, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 059, Runtime 0.867925, Loss 0.827929, forward nfe 44880, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 060, Runtime 0.633523, Loss 0.792985, forward nfe 45520, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 061, Runtime 0.617572, Loss 0.840430, forward nfe 46154, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 062, Runtime 0.616284, Loss 0.828796, forward nfe 46782, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 063, Runtime 0.609762, Loss 0.778356, forward nfe 47410, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 064, Runtime 0.630498, Loss 0.706183, forward nfe 48026, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 065, Runtime 0.626915, Loss 0.736768, forward nfe 48642, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 066, Runtime 0.621666, Loss 0.770649, forward nfe 49246, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 067, Runtime 0.611682, Loss 0.746219, forward nfe 49844, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 068, Runtime 0.604560, Loss 0.709960, forward nfe 50436, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 069, Runtime 0.623409, Loss 0.646479, forward nfe 51034, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 070, Runtime 0.612262, Loss 0.631250, forward nfe 51632, backward nfe 0, Train: 0.8143, Val: 0.8213, Test: 0.7939, Best time: 128.0000
Epoch: 071, Runtime 0.601082, Loss 0.698616, forward nfe 52224, backward nfe 0, Train: 0.8500, Val: 0.8235, Test: 0.8010, Best time: 48.6179
Epoch: 072, Runtime 0.597827, Loss 0.709896, forward nfe 52810, backward nfe 0, Train: 0.8500, Val: 0.8235, Test: 0.8010, Best time: 128.0000
Epoch: 073, Runtime 0.589210, Loss 0.600577, forward nfe 53384, backward nfe 0, Train: 0.8500, Val: 0.8235, Test: 0.8010, Best time: 128.0000
Epoch: 074, Runtime 0.579979, Loss 0.687394, forward nfe 53952, backward nfe 0, Train: 0.8500, Val: 0.8235, Test: 0.8010, Best time: 128.0000
Epoch: 075, Runtime 0.581904, Loss 0.817984, forward nfe 54514, backward nfe 0, Train: 0.8500, Val: 0.8235, Test: 0.8010, Best time: 128.0000
Epoch: 076, Runtime 0.579093, Loss 0.702602, forward nfe 55082, backward nfe 0, Train: 0.8500, Val: 0.8235, Test: 0.8010, Best time: 128.0000
Epoch: 077, Runtime 0.576041, Loss 0.691806, forward nfe 55638, backward nfe 0, Train: 0.8500, Val: 0.8235, Test: 0.8010, Best time: 128.0000
Epoch: 078, Runtime 0.577929, Loss 0.666759, forward nfe 56194, backward nfe 0, Train: 0.8500, Val: 0.8235, Test: 0.8010, Best time: 128.0000
Epoch: 079, Runtime 0.573058, Loss 0.659650, forward nfe 56750, backward nfe 0, Train: 0.8500, Val: 0.8235, Test: 0.8010, Best time: 128.0000
Epoch: 080, Runtime 0.569387, Loss 0.575073, forward nfe 57300, backward nfe 0, Train: 0.8500, Val: 0.8235, Test: 0.8010, Best time: 128.0000
Epoch: 081, Runtime 0.649264, Loss 0.625773, forward nfe 57844, backward nfe 0, Train: 0.8500, Val: 0.8235, Test: 0.8010, Best time: 128.0000
Epoch: 082, Runtime 0.557769, Loss 0.629415, forward nfe 58382, backward nfe 0, Train: 0.8286, Val: 0.8272, Test: 0.8193, Best time: 110.3951
Epoch: 083, Runtime 0.554977, Loss 0.642892, forward nfe 58926, backward nfe 0, Train: 0.8286, Val: 0.8272, Test: 0.8193, Best time: 128.0000
Epoch: 084, Runtime 0.554853, Loss 0.612889, forward nfe 59464, backward nfe 0, Train: 0.8286, Val: 0.8272, Test: 0.8193, Best time: 128.0000
Epoch: 085, Runtime 0.532190, Loss 0.632574, forward nfe 59996, backward nfe 0, Train: 0.8286, Val: 0.8272, Test: 0.8193, Best time: 128.0000
Epoch: 086, Runtime 0.537885, Loss 0.624639, forward nfe 60510, backward nfe 0, Train: 0.8286, Val: 0.8272, Test: 0.8193, Best time: 128.0000
Epoch: 087, Runtime 0.539102, Loss 0.558019, forward nfe 61030, backward nfe 0, Train: 0.8643, Val: 0.8316, Test: 0.8223, Best time: 75.1562
Epoch: 088, Runtime 0.529043, Loss 0.607160, forward nfe 61550, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 92.2953
Epoch: 089, Runtime 0.526772, Loss 0.558959, forward nfe 62058, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 128.0000
Epoch: 090, Runtime 0.528400, Loss 0.511542, forward nfe 62566, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 128.0000
Epoch: 091, Runtime 0.529933, Loss 0.581655, forward nfe 63068, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 128.0000
Epoch: 092, Runtime 0.729607, Loss 0.484476, forward nfe 63570, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 128.0000
Epoch: 093, Runtime 0.502930, Loss 0.643564, forward nfe 64054, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 128.0000
Epoch: 094, Runtime 0.507689, Loss 0.682333, forward nfe 64544, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 128.0000
Epoch: 095, Runtime 0.495492, Loss 0.522048, forward nfe 65034, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 128.0000
Epoch: 096, Runtime 0.500247, Loss 0.534441, forward nfe 65512, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 128.0000
Epoch: 097, Runtime 0.497728, Loss 0.624712, forward nfe 65990, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 128.0000
Epoch: 098, Runtime 0.495806, Loss 0.546070, forward nfe 66468, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 128.0000
Epoch: 099, Runtime 0.494650, Loss 0.520513, forward nfe 66940, backward nfe 0, Train: 0.8643, Val: 0.8346, Test: 0.8244, Best time: 128.0000
best val accuracy 0.834559 with test accuracy 0.824365 at epoch 88 and best time 128.000000
[INFO] Experiment mode is :  ON
[INFO] ODE function :  laplacian
[INFO] Block type :  attention
[INFO] T value :  128.0
[INFO] L1 regularization on :  False
[INFO] L1 reg coefficient :  0.001
GNNEarly
m1.module.weight
torch.Size([80, 1433])
m1.module.bias
torch.Size([80])
m2.module.weight
torch.Size([7, 80])
m2.module.bias
torch.Size([7])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
odeblock.multihead_att_layer.Q.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.Q.bias
torch.Size([128])
odeblock.multihead_att_layer.V.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.V.bias
torch.Size([128])
odeblock.multihead_att_layer.K.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.K.bias
torch.Size([128])
odeblock.multihead_att_layer.Wout.weight
torch.Size([80, 16])
odeblock.multihead_att_layer.Wout.bias
torch.Size([80])
Epoch: 001, Runtime 0.882117, Loss 1.947207, forward nfe 242, backward nfe 0, Train: 0.2429, Val: 0.2971, Test: 0.2985, Best time: 0.0973
Epoch: 002, Runtime 0.910299, Loss 1.889197, forward nfe 1092, backward nfe 0, Train: 0.4643, Val: 0.4596, Test: 0.4701, Best time: 0.0935
Epoch: 003, Runtime 0.870147, Loss 1.803500, forward nfe 1942, backward nfe 0, Train: 0.5071, Val: 0.5191, Test: 0.5381, Best time: 4.2070
Epoch: 004, Runtime 0.869677, Loss 1.695321, forward nfe 2792, backward nfe 0, Train: 0.6714, Val: 0.6551, Test: 0.6487, Best time: 2.1616
Epoch: 005, Runtime 0.871172, Loss 1.488043, forward nfe 3642, backward nfe 0, Train: 0.7714, Val: 0.7287, Test: 0.7716, Best time: 13.7370
Epoch: 006, Runtime 0.879469, Loss 1.419540, forward nfe 4486, backward nfe 0, Train: 0.7714, Val: 0.7287, Test: 0.7716, Best time: 128.0000
Epoch: 007, Runtime 0.855021, Loss 1.268011, forward nfe 5324, backward nfe 0, Train: 0.7714, Val: 0.7287, Test: 0.7716, Best time: 128.0000
Epoch: 008, Runtime 0.854949, Loss 1.194109, forward nfe 6162, backward nfe 0, Train: 0.7714, Val: 0.7287, Test: 0.7716, Best time: 128.0000
Epoch: 009, Runtime 0.853838, Loss 1.087326, forward nfe 7000, backward nfe 0, Train: 0.7786, Val: 0.7684, Test: 0.7909, Best time: 26.9076
Epoch: 010, Runtime 0.850739, Loss 1.053315, forward nfe 7826, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 22.7499
Epoch: 011, Runtime 0.817338, Loss 1.032669, forward nfe 8658, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 012, Runtime 0.813761, Loss 0.929834, forward nfe 9484, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 013, Runtime 0.849996, Loss 0.953397, forward nfe 10316, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 014, Runtime 0.840869, Loss 0.875382, forward nfe 11130, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 015, Runtime 0.825813, Loss 0.970625, forward nfe 11950, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 016, Runtime 0.810586, Loss 0.795574, forward nfe 12752, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 017, Runtime 0.800897, Loss 0.917597, forward nfe 13548, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 018, Runtime 0.801979, Loss 0.839793, forward nfe 14338, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 019, Runtime 0.798464, Loss 0.916349, forward nfe 15122, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 020, Runtime 0.793215, Loss 0.751588, forward nfe 15900, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 021, Runtime 0.789961, Loss 0.808790, forward nfe 16678, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 022, Runtime 0.774995, Loss 0.792036, forward nfe 17450, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 023, Runtime 0.779342, Loss 0.756555, forward nfe 18210, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 024, Runtime 0.762225, Loss 0.709192, forward nfe 18964, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 025, Runtime 0.752742, Loss 0.739622, forward nfe 19712, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 026, Runtime 0.749549, Loss 0.776717, forward nfe 20448, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 027, Runtime 0.746978, Loss 0.778227, forward nfe 21184, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 028, Runtime 0.735499, Loss 0.750507, forward nfe 21908, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 029, Runtime 0.733445, Loss 0.698284, forward nfe 22626, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 030, Runtime 0.717676, Loss 0.721146, forward nfe 23338, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 031, Runtime 0.720451, Loss 0.755900, forward nfe 24038, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 032, Runtime 0.711435, Loss 0.776279, forward nfe 24726, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 033, Runtime 0.696346, Loss 0.725306, forward nfe 25414, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 034, Runtime 0.698677, Loss 0.837435, forward nfe 26096, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 035, Runtime 0.693389, Loss 0.729170, forward nfe 26772, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 036, Runtime 0.688135, Loss 0.690825, forward nfe 27442, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 037, Runtime 0.683008, Loss 0.692775, forward nfe 28118, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 038, Runtime 0.673093, Loss 0.702579, forward nfe 28782, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 039, Runtime 0.668517, Loss 0.657634, forward nfe 29446, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 040, Runtime 0.670957, Loss 0.663260, forward nfe 30098, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 041, Runtime 0.662456, Loss 0.703066, forward nfe 30750, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 042, Runtime 0.651213, Loss 0.725551, forward nfe 31390, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 043, Runtime 0.666319, Loss 0.613313, forward nfe 32024, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 044, Runtime 0.729179, Loss 0.760308, forward nfe 32652, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 045, Runtime 0.626762, Loss 0.695852, forward nfe 33268, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 046, Runtime 0.627839, Loss 0.790585, forward nfe 33884, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 047, Runtime 0.617580, Loss 0.646514, forward nfe 34488, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 048, Runtime 0.616742, Loss 0.637331, forward nfe 35086, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 049, Runtime 0.825630, Loss 0.716920, forward nfe 35684, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 050, Runtime 0.592661, Loss 0.554521, forward nfe 36264, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 051, Runtime 0.584191, Loss 0.749208, forward nfe 36844, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 052, Runtime 0.582057, Loss 0.673214, forward nfe 37424, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 053, Runtime 0.581301, Loss 0.709264, forward nfe 37986, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 054, Runtime 0.571416, Loss 0.796565, forward nfe 38548, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 055, Runtime 0.566032, Loss 0.692712, forward nfe 39098, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 056, Runtime 0.569405, Loss 0.796247, forward nfe 39648, backward nfe 0, Train: 0.8214, Val: 0.7926, Test: 0.8213, Best time: 128.0000
Epoch: 057, Runtime 0.566098, Loss 0.601159, forward nfe 40198, backward nfe 0, Train: 0.8786, Val: 0.8044, Test: 0.8142, Best time: 48.5955
Epoch: 058, Runtime 0.558713, Loss 0.670702, forward nfe 40742, backward nfe 0, Train: 0.8786, Val: 0.8044, Test: 0.8142, Best time: 128.0000
Epoch: 059, Runtime 0.553435, Loss 0.526898, forward nfe 41280, backward nfe 0, Train: 0.8786, Val: 0.8044, Test: 0.8142, Best time: 128.0000
Epoch: 060, Runtime 0.553824, Loss 0.644587, forward nfe 41818, backward nfe 0, Train: 0.8786, Val: 0.8044, Test: 0.8142, Best time: 128.0000
Epoch: 061, Runtime 0.530937, Loss 0.545230, forward nfe 42344, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 57.8341
Epoch: 062, Runtime 0.535284, Loss 0.619966, forward nfe 42864, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 063, Runtime 0.533046, Loss 0.495324, forward nfe 43384, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 064, Runtime 0.534499, Loss 0.554427, forward nfe 43898, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 065, Runtime 0.524285, Loss 0.515761, forward nfe 44412, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 066, Runtime 0.526008, Loss 0.486426, forward nfe 44920, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 067, Runtime 0.521819, Loss 0.613814, forward nfe 45428, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 068, Runtime 0.513224, Loss 0.547138, forward nfe 45918, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 069, Runtime 0.510865, Loss 0.619522, forward nfe 46408, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 070, Runtime 0.503310, Loss 0.607290, forward nfe 46904, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 071, Runtime 0.507185, Loss 0.532668, forward nfe 47388, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 072, Runtime 0.500478, Loss 0.716931, forward nfe 47872, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 073, Runtime 0.499199, Loss 0.462751, forward nfe 48350, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 074, Runtime 0.496687, Loss 0.601281, forward nfe 48828, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 075, Runtime 0.503341, Loss 0.536707, forward nfe 49306, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 076, Runtime 0.490411, Loss 0.767471, forward nfe 49784, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 077, Runtime 0.496582, Loss 0.406517, forward nfe 50256, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 078, Runtime 0.478585, Loss 0.564997, forward nfe 50716, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 079, Runtime 0.479245, Loss 0.502749, forward nfe 51176, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 080, Runtime 0.474250, Loss 0.491702, forward nfe 51624, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 081, Runtime 0.468959, Loss 0.507580, forward nfe 52078, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 082, Runtime 0.459366, Loss 0.450373, forward nfe 52526, backward nfe 0, Train: 0.9143, Val: 0.8169, Test: 0.8294, Best time: 128.0000
Epoch: 083, Runtime 0.466393, Loss 0.488079, forward nfe 52968, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 142.4924
Epoch: 084, Runtime 0.473701, Loss 0.464185, forward nfe 53410, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 085, Runtime 0.467112, Loss 0.477492, forward nfe 53852, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 086, Runtime 0.683900, Loss 0.405159, forward nfe 54288, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 087, Runtime 0.456565, Loss 0.467883, forward nfe 54724, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 088, Runtime 0.455999, Loss 0.398066, forward nfe 55160, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 089, Runtime 0.450257, Loss 0.516569, forward nfe 55596, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 090, Runtime 0.450610, Loss 0.434082, forward nfe 56020, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 091, Runtime 0.451676, Loss 0.537021, forward nfe 56444, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 092, Runtime 0.445972, Loss 0.437759, forward nfe 56868, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 093, Runtime 0.435529, Loss 0.446030, forward nfe 57280, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 094, Runtime 0.433298, Loss 0.452605, forward nfe 57692, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 095, Runtime 0.429946, Loss 0.477639, forward nfe 58104, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 096, Runtime 0.438618, Loss 0.473394, forward nfe 58510, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 097, Runtime 0.424860, Loss 0.422786, forward nfe 58916, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 098, Runtime 0.437620, Loss 0.433183, forward nfe 59322, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
Epoch: 099, Runtime 0.443934, Loss 0.396861, forward nfe 59728, backward nfe 0, Train: 0.9143, Val: 0.8176, Test: 0.8457, Best time: 128.0000
best val accuracy 0.817647 with test accuracy 0.845685 at epoch 83 and best time 128.000000
[INFO] Experiment mode is :  ON
[INFO] ODE function :  laplacian
[INFO] Block type :  attention
[INFO] T value :  128.0
[INFO] L1 regularization on :  False
[INFO] L1 reg coefficient :  0.001
GNNEarly
m1.module.weight
torch.Size([80, 1433])
m1.module.bias
torch.Size([80])
m2.module.weight
torch.Size([7, 80])
m2.module.bias
torch.Size([7])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
odeblock.multihead_att_layer.Q.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.Q.bias
torch.Size([128])
odeblock.multihead_att_layer.V.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.V.bias
torch.Size([128])
odeblock.multihead_att_layer.K.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.K.bias
torch.Size([128])
odeblock.multihead_att_layer.Wout.weight
torch.Size([80, 16])
odeblock.multihead_att_layer.Wout.bias
torch.Size([80])
Epoch: 001, Runtime 0.888225, Loss 1.948152, forward nfe 242, backward nfe 0, Train: 0.2571, Val: 0.3301, Test: 0.3208, Best time: 0.0949
Epoch: 002, Runtime 0.868853, Loss 1.960247, forward nfe 1092, backward nfe 0, Train: 0.4143, Val: 0.4265, Test: 0.4254, Best time: 5.6668
Epoch: 003, Runtime 0.880329, Loss 1.858955, forward nfe 1942, backward nfe 0, Train: 0.5000, Val: 0.4691, Test: 0.4589, Best time: 3.5208
Epoch: 004, Runtime 0.836780, Loss 1.834233, forward nfe 2792, backward nfe 0, Train: 0.5929, Val: 0.5721, Test: 0.5655, Best time: 3.4818
Epoch: 005, Runtime 0.870177, Loss 1.699661, forward nfe 3642, backward nfe 0, Train: 0.6786, Val: 0.7588, Test: 0.7462, Best time: 10.2260
Epoch: 006, Runtime 0.878471, Loss 1.552125, forward nfe 4492, backward nfe 0, Train: 0.6786, Val: 0.7588, Test: 0.7462, Best time: 128.0000
Epoch: 007, Runtime 0.861337, Loss 1.414294, forward nfe 5336, backward nfe 0, Train: 0.7143, Val: 0.7728, Test: 0.7604, Best time: 14.8338
Epoch: 008, Runtime 0.856981, Loss 1.244190, forward nfe 6174, backward nfe 0, Train: 0.7143, Val: 0.7728, Test: 0.7604, Best time: 128.0000
Epoch: 009, Runtime 0.854488, Loss 1.104553, forward nfe 7012, backward nfe 0, Train: 0.7714, Val: 0.7875, Test: 0.7553, Best time: 48.9348
Epoch: 010, Runtime 0.858126, Loss 1.011346, forward nfe 7850, backward nfe 0, Train: 0.7857, Val: 0.7926, Test: 0.7726, Best time: 26.4267
Epoch: 011, Runtime 0.849035, Loss 0.951439, forward nfe 8676, backward nfe 0, Train: 0.8071, Val: 0.8015, Test: 0.7909, Best time: 31.8247
Epoch: 012, Runtime 0.858003, Loss 0.896008, forward nfe 9514, backward nfe 0, Train: 0.8143, Val: 0.8140, Test: 0.7858, Best time: 20.7808
Epoch: 013, Runtime 0.850385, Loss 0.843495, forward nfe 10340, backward nfe 0, Train: 0.8143, Val: 0.8140, Test: 0.7858, Best time: 128.0000
Epoch: 014, Runtime 0.842456, Loss 0.795587, forward nfe 11166, backward nfe 0, Train: 0.8143, Val: 0.8140, Test: 0.7858, Best time: 128.0000
Epoch: 015, Runtime 0.810935, Loss 0.779647, forward nfe 11992, backward nfe 0, Train: 0.8143, Val: 0.8140, Test: 0.7858, Best time: 128.0000
Epoch: 016, Runtime 0.840991, Loss 0.877431, forward nfe 12806, backward nfe 0, Train: 0.8143, Val: 0.8140, Test: 0.7858, Best time: 128.0000
Epoch: 017, Runtime 0.864737, Loss 0.744782, forward nfe 13620, backward nfe 0, Train: 0.8143, Val: 0.8140, Test: 0.7858, Best time: 128.0000
Epoch: 018, Runtime 0.795456, Loss 0.777472, forward nfe 14434, backward nfe 0, Train: 0.8071, Val: 0.8287, Test: 0.8122, Best time: 31.6021
Epoch: 019, Runtime 0.768473, Loss 0.789188, forward nfe 15230, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 69.7704
Epoch: 020, Runtime 0.776889, Loss 0.748424, forward nfe 16020, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 021, Runtime 0.790218, Loss 0.662445, forward nfe 16798, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 022, Runtime 0.783530, Loss 0.679230, forward nfe 17570, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 023, Runtime 0.783660, Loss 0.684784, forward nfe 18336, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 024, Runtime 0.768318, Loss 0.585739, forward nfe 19096, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 025, Runtime 0.769436, Loss 0.658577, forward nfe 19856, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 026, Runtime 0.756759, Loss 0.688665, forward nfe 20604, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 027, Runtime 0.749590, Loss 0.620898, forward nfe 21340, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 028, Runtime 0.745929, Loss 0.606709, forward nfe 22064, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 029, Runtime 0.722850, Loss 0.632731, forward nfe 22782, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 030, Runtime 0.728706, Loss 0.627739, forward nfe 23494, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 031, Runtime 0.721216, Loss 0.593980, forward nfe 24200, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 032, Runtime 0.705456, Loss 0.595376, forward nfe 24894, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 033, Runtime 0.715400, Loss 0.612903, forward nfe 25588, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 034, Runtime 0.691539, Loss 0.597374, forward nfe 26276, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 035, Runtime 0.671473, Loss 0.544293, forward nfe 26940, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 036, Runtime 0.670377, Loss 0.580169, forward nfe 27598, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 037, Runtime 0.669106, Loss 0.695864, forward nfe 28250, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 038, Runtime 0.658354, Loss 0.647219, forward nfe 28896, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 039, Runtime 0.658276, Loss 0.610655, forward nfe 29536, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 040, Runtime 0.647079, Loss 0.623415, forward nfe 30164, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 041, Runtime 0.637866, Loss 0.564721, forward nfe 30792, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 042, Runtime 0.633358, Loss 0.689707, forward nfe 31414, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 043, Runtime 0.627186, Loss 0.537603, forward nfe 32024, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 044, Runtime 0.615784, Loss 0.526804, forward nfe 32628, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 045, Runtime 0.851154, Loss 0.624552, forward nfe 33226, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 046, Runtime 0.607995, Loss 0.470477, forward nfe 33824, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 047, Runtime 0.600407, Loss 0.647007, forward nfe 34416, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 048, Runtime 0.613645, Loss 0.454729, forward nfe 35008, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 049, Runtime 0.599316, Loss 0.765385, forward nfe 35588, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 050, Runtime 0.598656, Loss 0.445059, forward nfe 36168, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 051, Runtime 0.581433, Loss 0.529179, forward nfe 36742, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 052, Runtime 0.585043, Loss 0.459151, forward nfe 37304, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 053, Runtime 0.581595, Loss 0.499211, forward nfe 37866, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 054, Runtime 0.585147, Loss 0.435411, forward nfe 38428, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 055, Runtime 0.591755, Loss 0.474628, forward nfe 38996, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 056, Runtime 0.565482, Loss 0.488580, forward nfe 39552, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 057, Runtime 0.560002, Loss 0.473251, forward nfe 40102, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 058, Runtime 0.557521, Loss 0.587309, forward nfe 40646, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 059, Runtime 0.555872, Loss 0.474384, forward nfe 41184, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 060, Runtime 0.558112, Loss 0.572909, forward nfe 41728, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 061, Runtime 0.549070, Loss 0.491784, forward nfe 42266, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 062, Runtime 0.552712, Loss 0.555175, forward nfe 42804, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 063, Runtime 0.558829, Loss 0.433909, forward nfe 43330, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 064, Runtime 0.533268, Loss 0.523250, forward nfe 43856, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 065, Runtime 0.534112, Loss 0.466345, forward nfe 44376, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 066, Runtime 0.532484, Loss 0.471813, forward nfe 44890, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 067, Runtime 0.532192, Loss 0.492903, forward nfe 45398, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 068, Runtime 0.527674, Loss 0.430673, forward nfe 45906, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 069, Runtime 0.524270, Loss 0.467654, forward nfe 46414, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 070, Runtime 0.525542, Loss 0.415055, forward nfe 46916, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 071, Runtime 0.519812, Loss 0.508147, forward nfe 47418, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 072, Runtime 0.511884, Loss 0.447973, forward nfe 47914, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 073, Runtime 0.509359, Loss 0.430358, forward nfe 48398, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 074, Runtime 0.506350, Loss 0.454401, forward nfe 48882, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 075, Runtime 0.498394, Loss 0.445604, forward nfe 49366, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 076, Runtime 0.501171, Loss 0.453940, forward nfe 49844, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 077, Runtime 0.497779, Loss 0.451525, forward nfe 50322, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 078, Runtime 0.488561, Loss 0.416078, forward nfe 50788, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 079, Runtime 0.488871, Loss 0.413631, forward nfe 51254, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 080, Runtime 0.485698, Loss 0.370049, forward nfe 51720, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 081, Runtime 0.697160, Loss 0.324225, forward nfe 52180, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 082, Runtime 0.486213, Loss 0.418175, forward nfe 52640, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 083, Runtime 0.476846, Loss 0.340278, forward nfe 53100, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 084, Runtime 0.468961, Loss 0.385658, forward nfe 53548, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 085, Runtime 0.472024, Loss 0.390991, forward nfe 53996, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 086, Runtime 0.466256, Loss 0.364487, forward nfe 54444, backward nfe 0, Train: 0.8071, Val: 0.8412, Test: 0.8254, Best time: 128.0000
Epoch: 087, Runtime 0.462292, Loss 0.319189, forward nfe 54886, backward nfe 0, Train: 0.8857, Val: 0.8434, Test: 0.8355, Best time: 173.1961
Epoch: 088, Runtime 0.467300, Loss 0.320996, forward nfe 55328, backward nfe 0, Train: 0.8857, Val: 0.8434, Test: 0.8355, Best time: 128.0000
Epoch: 089, Runtime 0.457992, Loss 0.311901, forward nfe 55764, backward nfe 0, Train: 0.8857, Val: 0.8434, Test: 0.8355, Best time: 128.0000
Epoch: 090, Runtime 0.459836, Loss 0.354348, forward nfe 56200, backward nfe 0, Train: 0.8857, Val: 0.8434, Test: 0.8355, Best time: 128.0000
Epoch: 091, Runtime 0.443515, Loss 0.360858, forward nfe 56630, backward nfe 0, Train: 0.9214, Val: 0.8441, Test: 0.8213, Best time: 140.5435
Epoch: 092, Runtime 0.451432, Loss 0.371182, forward nfe 57060, backward nfe 0, Train: 0.9214, Val: 0.8441, Test: 0.8213, Best time: 128.0000
Epoch: 093, Runtime 0.442181, Loss 0.344028, forward nfe 57490, backward nfe 0, Train: 0.9214, Val: 0.8441, Test: 0.8213, Best time: 128.0000
Epoch: 094, Runtime 0.455944, Loss 0.328749, forward nfe 57914, backward nfe 0, Train: 0.9214, Val: 0.8441, Test: 0.8213, Best time: 128.0000
Epoch: 095, Runtime 0.454829, Loss 0.325578, forward nfe 58344, backward nfe 0, Train: 0.9214, Val: 0.8441, Test: 0.8213, Best time: 128.0000
Epoch: 096, Runtime 0.448412, Loss 0.361391, forward nfe 58768, backward nfe 0, Train: 0.9214, Val: 0.8441, Test: 0.8213, Best time: 128.0000
Epoch: 097, Runtime 0.452315, Loss 0.306553, forward nfe 59198, backward nfe 0, Train: 0.9214, Val: 0.8441, Test: 0.8213, Best time: 128.0000
Epoch: 098, Runtime 0.437109, Loss 0.357465, forward nfe 59622, backward nfe 0, Train: 0.9214, Val: 0.8441, Test: 0.8213, Best time: 128.0000
Epoch: 099, Runtime 0.448382, Loss 0.396940, forward nfe 60040, backward nfe 0, Train: 0.9214, Val: 0.8441, Test: 0.8213, Best time: 128.0000
best val accuracy 0.844118 with test accuracy 0.821320 at epoch 91 and best time 128.000000
[INFO] Experiment mode is :  ON
[INFO] ODE function :  laplacian
[INFO] Block type :  attention
[INFO] T value :  128.0
[INFO] L1 regularization on :  False
[INFO] L1 reg coefficient :  0.001
GNNEarly
m1.module.weight
torch.Size([80, 1433])
m1.module.bias
torch.Size([80])
m2.module.weight
torch.Size([7, 80])
m2.module.bias
torch.Size([7])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
odeblock.multihead_att_layer.Q.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.Q.bias
torch.Size([128])
odeblock.multihead_att_layer.V.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.V.bias
torch.Size([128])
odeblock.multihead_att_layer.K.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.K.bias
torch.Size([128])
odeblock.multihead_att_layer.Wout.weight
torch.Size([80, 16])
odeblock.multihead_att_layer.Wout.bias
torch.Size([80])
Epoch: 001, Runtime 0.863727, Loss 1.948833, forward nfe 242, backward nfe 0, Train: 0.2786, Val: 0.2301, Test: 0.2000, Best time: 22.5816
Epoch: 002, Runtime 0.892010, Loss 2.056394, forward nfe 1098, backward nfe 0, Train: 0.2786, Val: 0.2301, Test: 0.2000, Best time: 128.0000
Epoch: 003, Runtime 0.836840, Loss 1.993731, forward nfe 1954, backward nfe 0, Train: 0.2786, Val: 0.2301, Test: 0.2000, Best time: 128.0000
Epoch: 004, Runtime 0.886467, Loss 1.925850, forward nfe 2822, backward nfe 0, Train: 0.2786, Val: 0.2301, Test: 0.2000, Best time: 128.0000
Epoch: 005, Runtime 0.878350, Loss 1.891921, forward nfe 3684, backward nfe 0, Train: 0.4071, Val: 0.3868, Test: 0.3655, Best time: 3.6474
Epoch: 006, Runtime 0.846568, Loss 1.841328, forward nfe 4546, backward nfe 0, Train: 0.4714, Val: 0.4404, Test: 0.4447, Best time: 3.4323
Epoch: 007, Runtime 0.852251, Loss 1.777342, forward nfe 5396, backward nfe 0, Train: 0.5571, Val: 0.4993, Test: 0.4904, Best time: 7.1653
Epoch: 008, Runtime 0.842040, Loss 1.691918, forward nfe 6252, backward nfe 0, Train: 0.6857, Val: 0.5478, Test: 0.5462, Best time: 10.1769
Epoch: 009, Runtime 0.846833, Loss 1.611733, forward nfe 7108, backward nfe 0, Train: 0.6643, Val: 0.6426, Test: 0.6365, Best time: 13.2092
Epoch: 010, Runtime 0.830703, Loss 1.498911, forward nfe 7958, backward nfe 0, Train: 0.7714, Val: 0.7301, Test: 0.7157, Best time: 96.1734
Epoch: 011, Runtime 0.827177, Loss 1.385859, forward nfe 8802, backward nfe 0, Train: 0.7714, Val: 0.7301, Test: 0.7157, Best time: 128.0000
Epoch: 012, Runtime 0.828528, Loss 1.313092, forward nfe 9646, backward nfe 0, Train: 0.7714, Val: 0.7301, Test: 0.7157, Best time: 128.0000
Epoch: 013, Runtime 0.833936, Loss 1.202962, forward nfe 10490, backward nfe 0, Train: 0.7357, Val: 0.7309, Test: 0.7320, Best time: 25.2748
Epoch: 014, Runtime 0.839423, Loss 1.146813, forward nfe 11340, backward nfe 0, Train: 0.7786, Val: 0.7449, Test: 0.7391, Best time: 67.7528
Epoch: 015, Runtime 0.860358, Loss 1.061580, forward nfe 12178, backward nfe 0, Train: 0.7786, Val: 0.7449, Test: 0.7391, Best time: 128.0000
Epoch: 016, Runtime 0.855011, Loss 0.998460, forward nfe 13016, backward nfe 0, Train: 0.7786, Val: 0.7449, Test: 0.7391, Best time: 128.0000
Epoch: 017, Runtime 0.858130, Loss 0.930162, forward nfe 13854, backward nfe 0, Train: 0.7286, Val: 0.7750, Test: 0.7624, Best time: 129.0501
Epoch: 018, Runtime 0.819234, Loss 0.950976, forward nfe 14692, backward nfe 0, Train: 0.7286, Val: 0.7750, Test: 0.7624, Best time: 128.0000
Epoch: 019, Runtime 0.811333, Loss 0.853295, forward nfe 15518, backward nfe 0, Train: 0.7286, Val: 0.7750, Test: 0.7624, Best time: 128.0000
Epoch: 020, Runtime 0.850844, Loss 0.838399, forward nfe 16350, backward nfe 0, Train: 0.7286, Val: 0.7750, Test: 0.7624, Best time: 128.0000
Epoch: 021, Runtime 0.874673, Loss 0.811746, forward nfe 17182, backward nfe 0, Train: 0.7571, Val: 0.7904, Test: 0.7645, Best time: 113.1867
Epoch: 022, Runtime 0.774685, Loss 0.852243, forward nfe 18002, backward nfe 0, Train: 0.7571, Val: 0.7904, Test: 0.7645, Best time: 128.0000
Epoch: 023, Runtime 0.778082, Loss 0.841232, forward nfe 18822, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 65.8098
Epoch: 024, Runtime 0.772072, Loss 0.782673, forward nfe 19636, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 025, Runtime 0.762294, Loss 0.798902, forward nfe 20444, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 026, Runtime 0.756439, Loss 0.748085, forward nfe 21240, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 027, Runtime 0.749083, Loss 0.735650, forward nfe 22036, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 028, Runtime 0.748841, Loss 0.808943, forward nfe 22820, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 029, Runtime 0.743278, Loss 0.840892, forward nfe 23604, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 030, Runtime 0.738381, Loss 0.738318, forward nfe 24382, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 031, Runtime 0.722774, Loss 0.905104, forward nfe 25154, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 032, Runtime 0.725023, Loss 0.757910, forward nfe 25914, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 033, Runtime 0.702870, Loss 0.836990, forward nfe 26668, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 034, Runtime 0.703618, Loss 0.695917, forward nfe 27410, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 035, Runtime 0.740849, Loss 0.808230, forward nfe 28158, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 036, Runtime 0.733258, Loss 0.685201, forward nfe 28906, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 037, Runtime 0.735378, Loss 0.716177, forward nfe 29636, backward nfe 0, Train: 0.7786, Val: 0.8118, Test: 0.7878, Best time: 128.0000
Epoch: 038, Runtime 0.730303, Loss 0.692082, forward nfe 30366, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 76.5341
Epoch: 039, Runtime 0.908434, Loss 0.651660, forward nfe 31090, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 040, Runtime 0.707792, Loss 0.702438, forward nfe 31808, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 041, Runtime 0.706204, Loss 0.638795, forward nfe 32520, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 042, Runtime 0.701698, Loss 0.685592, forward nfe 33220, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 043, Runtime 0.699100, Loss 0.629821, forward nfe 33908, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 044, Runtime 0.683148, Loss 0.640567, forward nfe 34602, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 045, Runtime 0.684376, Loss 0.634656, forward nfe 35290, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 046, Runtime 0.681298, Loss 0.577522, forward nfe 35972, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 047, Runtime 0.666915, Loss 0.590433, forward nfe 36648, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 048, Runtime 0.675140, Loss 0.722298, forward nfe 37318, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 049, Runtime 0.660732, Loss 0.551441, forward nfe 37976, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 050, Runtime 0.655954, Loss 0.789436, forward nfe 38634, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 051, Runtime 0.650246, Loss 0.638618, forward nfe 39286, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 052, Runtime 0.644990, Loss 0.783463, forward nfe 39938, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 053, Runtime 0.643565, Loss 0.623673, forward nfe 40584, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 054, Runtime 0.772054, Loss 0.866134, forward nfe 41230, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 055, Runtime 0.636700, Loss 0.569300, forward nfe 41870, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 056, Runtime 0.612920, Loss 0.644825, forward nfe 42504, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 057, Runtime 0.612541, Loss 0.528223, forward nfe 43138, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 058, Runtime 0.606981, Loss 0.628385, forward nfe 43772, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 059, Runtime 0.605907, Loss 0.581919, forward nfe 44400, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 060, Runtime 0.598247, Loss 0.558939, forward nfe 45028, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 061, Runtime 0.606291, Loss 0.538823, forward nfe 45644, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 062, Runtime 0.599191, Loss 0.517390, forward nfe 46266, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 063, Runtime 0.621981, Loss 0.493575, forward nfe 46882, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 064, Runtime 0.601623, Loss 0.567662, forward nfe 47486, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 065, Runtime 0.608985, Loss 0.573503, forward nfe 48090, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 066, Runtime 0.599317, Loss 0.631117, forward nfe 48694, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 067, Runtime 0.604488, Loss 0.526034, forward nfe 49292, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 068, Runtime 0.606564, Loss 0.533196, forward nfe 49890, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 069, Runtime 0.608640, Loss 0.575828, forward nfe 50488, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 070, Runtime 0.610973, Loss 0.522028, forward nfe 51080, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 071, Runtime 0.724094, Loss 0.625426, forward nfe 51672, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 072, Runtime 0.582110, Loss 0.504597, forward nfe 52258, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 073, Runtime 0.576558, Loss 0.514880, forward nfe 52838, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 074, Runtime 0.590987, Loss 0.563541, forward nfe 53412, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 075, Runtime 0.575706, Loss 0.487356, forward nfe 53986, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 076, Runtime 0.587067, Loss 0.505015, forward nfe 54566, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 077, Runtime 0.575915, Loss 0.471398, forward nfe 55140, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 078, Runtime 0.576805, Loss 0.565148, forward nfe 55714, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 079, Runtime 0.568583, Loss 0.471148, forward nfe 56288, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 080, Runtime 0.564201, Loss 0.475350, forward nfe 56850, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 081, Runtime 0.556642, Loss 0.464129, forward nfe 57400, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 082, Runtime 0.554152, Loss 0.500485, forward nfe 57956, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 083, Runtime 0.558256, Loss 0.564547, forward nfe 58506, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 084, Runtime 0.569930, Loss 0.557663, forward nfe 59056, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 085, Runtime 0.566031, Loss 0.482080, forward nfe 59600, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 086, Runtime 0.543933, Loss 0.480605, forward nfe 60144, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 087, Runtime 0.540896, Loss 0.460554, forward nfe 60682, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 088, Runtime 0.535224, Loss 0.507328, forward nfe 61220, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 089, Runtime 0.544852, Loss 0.457839, forward nfe 61758, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 090, Runtime 0.526460, Loss 0.449147, forward nfe 62290, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 091, Runtime 0.528694, Loss 0.398569, forward nfe 62816, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 092, Runtime 0.531107, Loss 0.402504, forward nfe 63342, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 093, Runtime 0.522821, Loss 0.461325, forward nfe 63868, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 094, Runtime 0.518863, Loss 0.434954, forward nfe 64382, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 095, Runtime 0.510541, Loss 0.438154, forward nfe 64896, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 096, Runtime 0.518121, Loss 0.438469, forward nfe 65410, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 097, Runtime 0.514184, Loss 0.466028, forward nfe 65918, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 098, Runtime 0.512812, Loss 0.566123, forward nfe 66426, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
Epoch: 099, Runtime 0.511484, Loss 0.485869, forward nfe 66934, backward nfe 0, Train: 0.8500, Val: 0.8250, Test: 0.8010, Best time: 128.0000
best val accuracy 0.825000 with test accuracy 0.801015 at epoch 38 and best time 128.000000
[INFO] Experiment mode is :  ON
[INFO] ODE function :  laplacian
[INFO] Block type :  attention
[INFO] T value :  128.0
[INFO] L1 regularization on :  False
[INFO] L1 reg coefficient :  0.001
GNNEarly
m1.module.weight
torch.Size([80, 1433])
m1.module.bias
torch.Size([80])
m2.module.weight
torch.Size([7, 80])
m2.module.bias
torch.Size([7])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
odeblock.multihead_att_layer.Q.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.Q.bias
torch.Size([128])
odeblock.multihead_att_layer.V.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.V.bias
torch.Size([128])
odeblock.multihead_att_layer.K.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.K.bias
torch.Size([128])
odeblock.multihead_att_layer.Wout.weight
torch.Size([80, 16])
odeblock.multihead_att_layer.Wout.bias
torch.Size([80])
Epoch: 001, Runtime 0.850222, Loss 1.948089, forward nfe 242, backward nfe 0, Train: 0.3929, Val: 0.2985, Test: 0.3046, Best time: 192.9787
Epoch: 002, Runtime 0.852401, Loss 1.874550, forward nfe 1098, backward nfe 0, Train: 0.5786, Val: 0.6199, Test: 0.6325, Best time: 9.7895
Epoch: 003, Runtime 0.868119, Loss 1.760495, forward nfe 1954, backward nfe 0, Train: 0.5786, Val: 0.6199, Test: 0.6325, Best time: 128.0000
Epoch: 004, Runtime 0.836601, Loss 1.581841, forward nfe 2804, backward nfe 0, Train: 0.5786, Val: 0.6199, Test: 0.6325, Best time: 128.0000
Epoch: 005, Runtime 0.842603, Loss 1.432810, forward nfe 3654, backward nfe 0, Train: 0.5786, Val: 0.6199, Test: 0.6325, Best time: 128.0000
Epoch: 006, Runtime 0.834717, Loss 1.355136, forward nfe 4492, backward nfe 0, Train: 0.8357, Val: 0.7816, Test: 0.7990, Best time: 30.2126
Epoch: 007, Runtime 0.830297, Loss 1.139224, forward nfe 5330, backward nfe 0, Train: 0.8357, Val: 0.7816, Test: 0.7990, Best time: 128.0000
Epoch: 008, Runtime 0.793905, Loss 1.113744, forward nfe 6168, backward nfe 0, Train: 0.8357, Val: 0.7816, Test: 0.7990, Best time: 128.0000
Epoch: 009, Runtime 0.824247, Loss 0.971906, forward nfe 7000, backward nfe 0, Train: 0.8357, Val: 0.7816, Test: 0.7990, Best time: 128.0000
Epoch: 010, Runtime 0.832836, Loss 0.882499, forward nfe 7832, backward nfe 0, Train: 0.8357, Val: 0.7816, Test: 0.7990, Best time: 128.0000
Epoch: 011, Runtime 0.820440, Loss 0.908644, forward nfe 8658, backward nfe 0, Train: 0.8357, Val: 0.7816, Test: 0.7990, Best time: 128.0000
Epoch: 012, Runtime 0.826049, Loss 0.864373, forward nfe 9490, backward nfe 0, Train: 0.8214, Val: 0.8081, Test: 0.8071, Best time: 15.1644
Epoch: 013, Runtime 0.809249, Loss 0.748997, forward nfe 10316, backward nfe 0, Train: 0.8214, Val: 0.8081, Test: 0.8071, Best time: 128.0000
Epoch: 014, Runtime 0.809281, Loss 0.746069, forward nfe 11136, backward nfe 0, Train: 0.8214, Val: 0.8081, Test: 0.8071, Best time: 128.0000
Epoch: 015, Runtime 0.811762, Loss 0.718139, forward nfe 11950, backward nfe 0, Train: 0.8214, Val: 0.8081, Test: 0.8071, Best time: 128.0000
Epoch: 016, Runtime 0.801745, Loss 0.665999, forward nfe 12758, backward nfe 0, Train: 0.8214, Val: 0.8081, Test: 0.8071, Best time: 128.0000
Epoch: 017, Runtime 0.779189, Loss 0.722035, forward nfe 13560, backward nfe 0, Train: 0.8214, Val: 0.8081, Test: 0.8071, Best time: 128.0000
Epoch: 018, Runtime 0.752091, Loss 0.648682, forward nfe 14350, backward nfe 0, Train: 0.8214, Val: 0.8081, Test: 0.8071, Best time: 128.0000
Epoch: 019, Runtime 0.740443, Loss 0.599235, forward nfe 15134, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8193, Best time: 48.5463
Epoch: 020, Runtime 0.774847, Loss 0.570944, forward nfe 15912, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8193, Best time: 128.0000
Epoch: 021, Runtime 0.757263, Loss 0.651200, forward nfe 16684, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8193, Best time: 128.0000
Epoch: 022, Runtime 0.753489, Loss 0.589517, forward nfe 17450, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8193, Best time: 128.0000
Epoch: 023, Runtime 0.739458, Loss 0.563972, forward nfe 18210, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8193, Best time: 128.0000
Epoch: 024, Runtime 0.743621, Loss 0.596479, forward nfe 18952, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8193, Best time: 128.0000
Epoch: 025, Runtime 0.733009, Loss 0.531559, forward nfe 19700, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8193, Best time: 128.0000
Epoch: 026, Runtime 0.727690, Loss 0.601736, forward nfe 20436, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8193, Best time: 128.0000
Epoch: 027, Runtime 0.704605, Loss 0.507685, forward nfe 21154, backward nfe 0, Train: 0.8429, Val: 0.8125, Test: 0.8193, Best time: 128.0000
Epoch: 028, Runtime 0.709738, Loss 0.725341, forward nfe 21866, backward nfe 0, Train: 0.8429, Val: 0.8132, Test: 0.8183, Best time: 52.4925
Epoch: 029, Runtime 0.714431, Loss 0.641021, forward nfe 22584, backward nfe 0, Train: 0.8429, Val: 0.8132, Test: 0.8183, Best time: 128.0000
Epoch: 030, Runtime 0.846853, Loss 0.679877, forward nfe 23296, backward nfe 0, Train: 0.8429, Val: 0.8132, Test: 0.8183, Best time: 128.0000
Epoch: 031, Runtime 0.693022, Loss 0.509626, forward nfe 23990, backward nfe 0, Train: 0.8429, Val: 0.8132, Test: 0.8183, Best time: 128.0000
Epoch: 032, Runtime 0.688361, Loss 0.565360, forward nfe 24684, backward nfe 0, Train: 0.8429, Val: 0.8132, Test: 0.8183, Best time: 128.0000
Epoch: 033, Runtime 0.687233, Loss 0.638490, forward nfe 25372, backward nfe 0, Train: 0.8714, Val: 0.8184, Test: 0.8305, Best time: 36.9493
Epoch: 034, Runtime 0.686089, Loss 0.428187, forward nfe 26060, backward nfe 0, Train: 0.8714, Val: 0.8184, Test: 0.8305, Best time: 128.0000
Epoch: 035, Runtime 0.768882, Loss 0.523756, forward nfe 26742, backward nfe 0, Train: 0.8714, Val: 0.8184, Test: 0.8305, Best time: 128.0000
Epoch: 036, Runtime 0.658091, Loss 0.468933, forward nfe 27406, backward nfe 0, Train: 0.8714, Val: 0.8184, Test: 0.8305, Best time: 128.0000
Epoch: 037, Runtime 0.657377, Loss 0.415690, forward nfe 28076, backward nfe 0, Train: 0.8714, Val: 0.8184, Test: 0.8305, Best time: 128.0000
Epoch: 038, Runtime 0.644461, Loss 0.455954, forward nfe 28740, backward nfe 0, Train: 0.8714, Val: 0.8184, Test: 0.8305, Best time: 128.0000
Epoch: 039, Runtime 0.656054, Loss 0.537909, forward nfe 29392, backward nfe 0, Train: 0.8714, Val: 0.8184, Test: 0.8305, Best time: 128.0000
Epoch: 040, Runtime 0.641789, Loss 0.411621, forward nfe 30044, backward nfe 0, Train: 0.8714, Val: 0.8184, Test: 0.8305, Best time: 128.0000
Epoch: 041, Runtime 0.620289, Loss 0.439615, forward nfe 30678, backward nfe 0, Train: 0.8714, Val: 0.8184, Test: 0.8305, Best time: 128.0000
Traceback (most recent call last):
  File "/home/administrator/hieu/graph-neural-pde/src/run_GNN.py", line 254, in main
    tmp_train_acc, tmp_val_acc, tmp_test_acc = this_test(model, data, pos_encoding, opt)
  File "/home/administrator/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/administrator/hieu/graph-neural-pde/src/run_GNN.py", line 138, in test
    logits, accs = model(feat, pos_encoding), []
  File "/home/administrator/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/administrator/hieu/graph-neural-pde/src/GNN_early.py", line 84, in forward
    z = self.odeblock(x)
  File "/home/administrator/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/administrator/hieu/graph-neural-pde/src/block_transformer_attention.py", line 59, in forward
    state_dt = integrator(
  File "/home/administrator/hieu/graph-neural-pde/src/early_stop_solver.py", line 301, in __call__
    t, solution = self.solver.integrate(t)
  File "/home/administrator/hieu/graph-neural-pde/src/early_stop_solver.py", line 65, in integrate
    new_t, y = self.advance(t[i])
  File "/home/administrator/hieu/graph-neural-pde/src/early_stop_solver.py", line 79, in advance
    train_acc, val_acc, test_acc = self.evaluate(self.rk_state)
  File "/home/administrator/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/administrator/hieu/graph-neural-pde/src/early_stop_solver.py", line 113, in evaluate
    t0, t1 = float(self.rk_state.t0), float(self.rk_state.t1)
KeyboardInterrupt
best val accuracy 0.818382 with test accuracy 0.830457 at epoch 33 and best time 128.000000
[INFO] Experiment mode is :  ON
[INFO] ODE function :  laplacian
[INFO] Block type :  attention
[INFO] T value :  128.0
[INFO] L1 regularization on :  False
[INFO] L1 reg coefficient :  0.001
GNNEarly
m1.module.weight
torch.Size([80, 1433])
m1.module.bias
torch.Size([80])
m2.module.weight
torch.Size([7, 80])
m2.module.bias
torch.Size([7])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([80, 80])
odeblock.odefunc.d
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([80, 80])
odeblock.reg_odefunc.odefunc.d
torch.Size([80])
odeblock.multihead_att_layer.Q.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.Q.bias
torch.Size([128])
odeblock.multihead_att_layer.V.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.V.bias
torch.Size([128])
odeblock.multihead_att_layer.K.weight
torch.Size([128, 80])
odeblock.multihead_att_layer.K.bias
torch.Size([128])
odeblock.multihead_att_layer.Wout.weight
torch.Size([80, 16])
odeblock.multihead_att_layer.Wout.bias
