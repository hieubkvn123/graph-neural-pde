****************** Extended Laplacian Function V.3 ******************
Clipping Bound =  0.05
Alpha =  1.0
*********************************************************************
****************** Extended Laplacian Function V.3 ******************
Clipping Bound =  0.05
Alpha =  1.0
*********************************************************************
GNNEarly
m1.module.weight
torch.Size([80, 1433])
m1.module.bias
torch.Size([80])
m2.module.weight
torch.Size([7, 80])
m2.module.bias
torch.Size([7])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.multihead_att_layer.Q.weight
torch.Size([128, 80])
odeblock.odefunc.multihead_att_layer.Q.bias
torch.Size([128])
odeblock.odefunc.multihead_att_layer.V.weight
torch.Size([128, 80])
odeblock.odefunc.multihead_att_layer.V.bias
torch.Size([128])
odeblock.odefunc.multihead_att_layer.K.weight
torch.Size([128, 80])
odeblock.odefunc.multihead_att_layer.K.bias
torch.Size([128])
odeblock.odefunc.multihead_att_layer.Wout.weight
torch.Size([80, 16])
odeblock.odefunc.multihead_att_layer.Wout.bias
torch.Size([80])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.multihead_att_layer.Q.weight
torch.Size([128, 80])
odeblock.reg_odefunc.odefunc.multihead_att_layer.Q.bias
torch.Size([128])
odeblock.reg_odefunc.odefunc.multihead_att_layer.V.weight
torch.Size([128, 80])
odeblock.reg_odefunc.odefunc.multihead_att_layer.V.bias
torch.Size([128])
odeblock.reg_odefunc.odefunc.multihead_att_layer.K.weight
torch.Size([128, 80])
odeblock.reg_odefunc.odefunc.multihead_att_layer.K.bias
torch.Size([128])
odeblock.reg_odefunc.odefunc.multihead_att_layer.Wout.weight
torch.Size([80, 16])
odeblock.reg_odefunc.odefunc.multihead_att_layer.Wout.bias
torch.Size([80])
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 001/100, Runtime 0.990064, Loss 1.945164, forward nfe 14, backward nfe 0, Train: 0.9214, Val: 0.6154, Test: 0.6020, Best time: 4.2837
/home/hieunm60/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py:11: UserWarning: Dopri5Solver: Unexpected arguments {'step_size': 1, 'max_iters': 100}
  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))
/home/hieunm60/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torchdiffeq/_impl/misc.py:11: UserWarning: EarlyStopDopri5: Unexpected arguments {'step_size': 1, 'max_iters': 100}
  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 002/100, Runtime 0.931067, Loss 1.723290, forward nfe 54, backward nfe 0, Train: 0.9929, Val: 0.6471, Test: 0.6284, Best time: 3.9490
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 003/100, Runtime 0.955335, Loss 1.386419, forward nfe 94, backward nfe 0, Train: 0.9929, Val: 0.6559, Test: 0.6437, Best time: 3.6839
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 004/100, Runtime 1.113403, Loss 1.062377, forward nfe 140, backward nfe 0, Train: 1.0000, Val: 0.6956, Test: 0.6761, Best time: 4.2690
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 005/100, Runtime 1.097721, Loss 0.744386, forward nfe 192, backward nfe 0, Train: 1.0000, Val: 0.7228, Test: 0.6964, Best time: 3.4574
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 006/100, Runtime 1.304711, Loss 0.516822, forward nfe 250, backward nfe 0, Train: 1.0000, Val: 0.7551, Test: 0.7086, Best time: 3.3191
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 007/100, Runtime 0.987221, Loss 0.351431, forward nfe 302, backward nfe 0, Train: 1.0000, Val: 0.7581, Test: 0.7249, Best time: 3.4547
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 008/100, Runtime 1.248083, Loss 0.226580, forward nfe 360, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 4.2736
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 009/100, Runtime 0.963138, Loss 0.135549, forward nfe 412, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 1.0000
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 010/100, Runtime 1.104414, Loss 0.111328, forward nfe 458, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 1.0000
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 011/100, Runtime 1.191412, Loss 0.081220, forward nfe 510, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 1.0000
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 012/100, Runtime 1.168351, Loss 0.101881, forward nfe 568, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 1.0000
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 013/100, Runtime 1.270502, Loss 0.080447, forward nfe 626, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 1.0000
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 014/100, Runtime 1.105937, Loss 0.066256, forward nfe 684, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 1.0000
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 015/100, Runtime 1.143102, Loss 0.072060, forward nfe 736, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 1.0000
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 016/100, Runtime 1.035424, Loss 0.070343, forward nfe 788, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 1.0000
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 017/100, Runtime 1.002871, Loss 0.066362, forward nfe 834, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 1.0000
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 018/100, Runtime 1.091913, Loss 0.068214, forward nfe 880, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 1.0000
K_d =  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',
       grad_fn=<ToCopyBackward0>)
Epoch: 019/100, Runtime 1.096293, Loss 0.081601, forward nfe 926, backward nfe 0, Train: 1.0000, Val: 0.7640, Test: 0.7330, Best time: 1.0000
Traceback (most recent call last):
  File "run_GNN.py", line 265, in main
    tmp_train_acc, tmp_val_acc, tmp_test_acc = this_test(model, data, pos_encoding, opt)
  File "/home/hieunm60/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "run_GNN.py", line 140, in test
    logits, accs = model(feat, pos_encoding), []
  File "/home/hieunm60/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/media/data-share/hieunm60/graph-neural-pde/src/GNN_early.py", line 84, in forward
    z = self.odeblock(x)
  File "/home/hieunm60/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/media/data-share/hieunm60/graph-neural-pde/src/block_constant.py", line 56, in forward
    state_dt = integrator(
  File "/media/data-share/hieunm60/graph-neural-pde/src/early_stop_solver.py", line 301, in __call__
    t, solution = self.solver.integrate(t)
  File "/media/data-share/hieunm60/graph-neural-pde/src/early_stop_solver.py", line 65, in integrate
    new_t, y = self.advance(t[i])
  File "/media/data-share/hieunm60/graph-neural-pde/src/early_stop_solver.py", line 79, in advance
    train_acc, val_acc, test_acc = self.evaluate(self.rk_state)
  File "/home/hieunm60/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/media/data-share/hieunm60/graph-neural-pde/src/early_stop_solver.py", line 119, in evaluate
    train_acc, val_acc, test_acc = self.ode_test(z)
  File "/home/hieunm60/anaconda3/envs/deepgrand/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/media/data-share/hieunm60/graph-neural-pde/src/early_stop_solver.py", line 93, in test
    acc = pred.eq(self.data.y[mask]).sum().item() / mask.sum().item()
KeyboardInterrupt
best val accuracy 0.763971 with test accuracy 0.732995 at epoch 8 and best time 1.000000