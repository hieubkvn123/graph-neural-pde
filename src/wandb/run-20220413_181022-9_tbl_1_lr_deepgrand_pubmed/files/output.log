[INFO] Experiment mode is :  ON
[INFO] ODE function :  ext_laplacian3
[INFO] Block type :  attention
[INFO] T value :  128.0
[INFO] L1 regularization on :  False
[INFO] L1 reg coefficient :  0.001
/home/administrator/anaconda3/envs/grand/lib/python3.7/site-packages/torchdiffeq/_impl/misc.py:11: UserWarning: Dopri5Solver: Unexpected arguments {'step_size': 1}
  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))
/home/administrator/anaconda3/envs/grand/lib/python3.7/site-packages/torchdiffeq/_impl/misc.py:11: UserWarning: AdaptiveHeunSolver: Unexpected arguments {'step_size': 1}
  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))
****************** Extended Laplacian Function V.3 ******************
Clipping Bound =  0.4
Alpha =  3.0
*********************************************************************
****************** Extended Laplacian Function V.3 ******************
Clipping Bound =  0.4
Alpha =  3.0
*********************************************************************
GNNEarly
m1.module.weight
torch.Size([128, 500])
m1.module.bias
torch.Size([128])
m2.module.weight
torch.Size([3, 128])
m2.module.bias
torch.Size([3])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([128, 128])
odeblock.odefunc.d
torch.Size([128])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([128, 128])
odeblock.reg_odefunc.odefunc.d
torch.Size([128])
odeblock.multihead_att_layer.Q.weight
torch.Size([16, 128])
odeblock.multihead_att_layer.Q.bias
torch.Size([16])
odeblock.multihead_att_layer.V.weight
torch.Size([16, 128])
odeblock.multihead_att_layer.V.bias
torch.Size([16])
odeblock.multihead_att_layer.K.weight
torch.Size([16, 128])
odeblock.multihead_att_layer.K.bias
torch.Size([16])
odeblock.multihead_att_layer.Wout.weight
torch.Size([128, 16])
odeblock.multihead_att_layer.Wout.bias
torch.Size([128])
/home/administrator/anaconda3/envs/grand/lib/python3.7/site-packages/torchdiffeq/_impl/misc.py:11: UserWarning: EarlyStopDopri5: Unexpected arguments {'step_size': 1}
  warnings.warn('{}: Unexpected arguments {}'.format(solver.__class__.__name__, unused_kwargs))
Epoch: 001/100, Runtime 0.631877, Loss 1.099818, forward nfe 38, backward nfe 12, Train: 0.7833, Val: 0.6465, Test: 0.6512, Best time: 3.4609
Epoch: 002/100, Runtime 0.700040, Loss 1.101638, forward nfe 264, backward nfe 34, Train: 0.7833, Val: 0.6465, Test: 0.6512, Best time: 128.0000
Epoch: 003/100, Runtime 0.717870, Loss 1.104870, forward nfe 478, backward nfe 59, Train: 0.7833, Val: 0.6465, Test: 0.6512, Best time: 128.0000
Epoch: 004/100, Runtime 0.711664, Loss 1.097961, forward nfe 686, backward nfe 89, Train: 0.7833, Val: 0.6465, Test: 0.6512, Best time: 128.0000
Epoch: 005/100, Runtime 3.036264, Loss 1.087899, forward nfe 894, backward nfe 311, Train: 0.7833, Val: 0.6465, Test: 0.6512, Best time: 128.0000
Epoch: 006/100, Runtime 1.650847, Loss 1.067984, forward nfe 1108, backward nfe 438, Train: 0.7833, Val: 0.6465, Test: 0.6512, Best time: 128.0000
Epoch: 007/100, Runtime 2.160934, Loss 1.034626, forward nfe 1328, backward nfe 651, Train: 0.7833, Val: 0.6465, Test: 0.6512, Best time: 128.0000
Epoch: 008/100, Runtime 2.346473, Loss 0.991103, forward nfe 1548, backward nfe 896, Train: 0.8667, Val: 0.7097, Test: 0.7102, Best time: 2.9909
Epoch: 009/100, Runtime 2.493793, Loss 0.930512, forward nfe 1768, backward nfe 1140, Train: 0.8500, Val: 0.7208, Test: 0.7234, Best time: 2.8466
Epoch: 010/100, Runtime 2.217903, Loss 0.860543, forward nfe 1982, backward nfe 1334, Train: 0.8667, Val: 0.7243, Test: 0.7220, Best time: 15.9535
Epoch: 011/100, Runtime 3.000113, Loss 0.773427, forward nfe 2202, backward nfe 1565, Train: 0.8500, Val: 0.7299, Test: 0.7222, Best time: 14.9908
Epoch: 012/100, Runtime 2.065828, Loss 0.719233, forward nfe 2428, backward nfe 1763, Train: 0.8333, Val: 0.7340, Test: 0.7226, Best time: 44.8968
Epoch: 013/100, Runtime 1.772796, Loss 0.661728, forward nfe 2654, backward nfe 1917, Train: 0.8333, Val: 0.7382, Test: 0.7304, Best time: 44.0207
Epoch: 014/100, Runtime 2.268609, Loss 0.562280, forward nfe 2880, backward nfe 2121, Train: 0.8333, Val: 0.7444, Test: 0.7354, Best time: 118.2385
Epoch: 015/100, Runtime 1.961175, Loss 0.481625, forward nfe 3106, backward nfe 2305, Train: 0.8667, Val: 0.7507, Test: 0.7475, Best time: 35.4539
Epoch: 016/100, Runtime 1.823201, Loss 0.461518, forward nfe 3332, backward nfe 2475, Train: 0.8667, Val: 0.7653, Test: 0.7567, Best time: 147.0049
Epoch: 017/100, Runtime 2.011312, Loss 0.372096, forward nfe 3552, backward nfe 2667, Train: 0.9167, Val: 0.7729, Test: 0.7693, Best time: 105.9666
Epoch: 018/100, Runtime 1.532193, Loss 0.354113, forward nfe 3778, backward nfe 2792, Train: 0.9167, Val: 0.7729, Test: 0.7693, Best time: 128.0000
Epoch: 019/100, Runtime 2.169564, Loss 0.288336, forward nfe 3992, backward nfe 3008, Train: 0.9167, Val: 0.7729, Test: 0.7693, Best time: 128.0000
Epoch: 020/100, Runtime 1.721997, Loss 0.250344, forward nfe 4212, backward nfe 3162, Train: 0.9167, Val: 0.7729, Test: 0.7693, Best time: 128.0000
Epoch: 021/100, Runtime 1.764749, Loss 0.285728, forward nfe 4426, backward nfe 3323, Train: 0.9167, Val: 0.7729, Test: 0.7693, Best time: 128.0000
Epoch: 022/100, Runtime 1.845497, Loss 0.261373, forward nfe 4646, backward nfe 3494, Train: 0.9167, Val: 0.7729, Test: 0.7693, Best time: 128.0000
Epoch: 023/100, Runtime 2.435824, Loss 0.308542, forward nfe 4860, backward nfe 3738, Train: 0.9000, Val: 0.7757, Test: 0.7725, Best time: 128.0000
Epoch: 024/100, Runtime 2.052010, Loss 0.244959, forward nfe 5068, backward nfe 3946, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 166.8455
Epoch: 025/100, Runtime 2.093231, Loss 0.212252, forward nfe 5276, backward nfe 4152, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 026/100, Runtime 1.886473, Loss 0.170221, forward nfe 5508, backward nfe 4328, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 027/100, Runtime 1.962332, Loss 0.204391, forward nfe 5728, backward nfe 4532, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 028/100, Runtime 1.772575, Loss 0.282107, forward nfe 5936, backward nfe 4713, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 029/100, Runtime 1.938339, Loss 0.189698, forward nfe 6156, backward nfe 4919, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 030/100, Runtime 1.954511, Loss 0.221260, forward nfe 6376, backward nfe 5119, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 031/100, Runtime 1.728499, Loss 0.202815, forward nfe 6596, backward nfe 5285, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 032/100, Runtime 1.928773, Loss 0.208080, forward nfe 6810, backward nfe 5473, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 033/100, Runtime 2.092425, Loss 0.284991, forward nfe 7030, backward nfe 5675, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 034/100, Runtime 1.976199, Loss 0.182806, forward nfe 7268, backward nfe 5844, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 035/100, Runtime 2.198920, Loss 0.183779, forward nfe 7488, backward nfe 6046, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 036/100, Runtime 1.804373, Loss 0.208248, forward nfe 7720, backward nfe 6209, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 037/100, Runtime 1.442675, Loss 0.213691, forward nfe 7952, backward nfe 6324, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 038/100, Runtime 1.526623, Loss 0.253268, forward nfe 8190, backward nfe 6446, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 039/100, Runtime 2.113539, Loss 0.241291, forward nfe 8422, backward nfe 6621, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 040/100, Runtime 1.768693, Loss 0.201054, forward nfe 8648, backward nfe 6773, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 041/100, Runtime 2.288738, Loss 0.209723, forward nfe 8874, backward nfe 6992, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 042/100, Runtime 1.447124, Loss 0.237640, forward nfe 9106, backward nfe 7113, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 043/100, Runtime 1.801191, Loss 0.146082, forward nfe 9338, backward nfe 7297, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 044/100, Runtime 1.920243, Loss 0.217789, forward nfe 9564, backward nfe 7473, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 045/100, Runtime 1.611751, Loss 0.147669, forward nfe 9796, backward nfe 7625, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 046/100, Runtime 1.763093, Loss 0.161185, forward nfe 10028, backward nfe 7794, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 047/100, Runtime 1.359547, Loss 0.230764, forward nfe 10254, backward nfe 7906, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 048/100, Runtime 1.447867, Loss 0.193813, forward nfe 10486, backward nfe 8033, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 049/100, Runtime 2.188520, Loss 0.149548, forward nfe 10712, backward nfe 8276, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 050/100, Runtime 1.609562, Loss 0.240086, forward nfe 10944, backward nfe 8441, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 051/100, Runtime 1.254821, Loss 0.170752, forward nfe 11164, backward nfe 8555, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 052/100, Runtime 2.012157, Loss 0.123336, forward nfe 11396, backward nfe 8764, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 053/100, Runtime 2.069433, Loss 0.175196, forward nfe 11616, backward nfe 8979, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 054/100, Runtime 2.081140, Loss 0.118979, forward nfe 11836, backward nfe 9196, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 055/100, Runtime 2.275582, Loss 0.174808, forward nfe 12068, backward nfe 9416, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 056/100, Runtime 1.288154, Loss 0.134366, forward nfe 12282, backward nfe 9522, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 057/100, Runtime 1.781677, Loss 0.109906, forward nfe 12514, backward nfe 9691, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 058/100, Runtime 1.736829, Loss 0.111527, forward nfe 12740, backward nfe 9858, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 059/100, Runtime 1.905443, Loss 0.176387, forward nfe 12972, backward nfe 10044, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 060/100, Runtime 1.850195, Loss 0.210394, forward nfe 13204, backward nfe 10211, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 061/100, Runtime 1.503630, Loss 0.176461, forward nfe 13436, backward nfe 10335, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 062/100, Runtime 1.917015, Loss 0.234559, forward nfe 13662, backward nfe 10520, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 063/100, Runtime 1.276376, Loss 0.191599, forward nfe 13894, backward nfe 10619, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 064/100, Runtime 1.581588, Loss 0.151830, forward nfe 14132, backward nfe 10756, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 065/100, Runtime 2.195945, Loss 0.222634, forward nfe 14364, backward nfe 10975, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 066/100, Runtime 1.744065, Loss 0.173111, forward nfe 14596, backward nfe 11137, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 067/100, Runtime 1.784194, Loss 0.120624, forward nfe 14822, backward nfe 11291, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 068/100, Runtime 1.697206, Loss 0.182580, forward nfe 15054, backward nfe 11430, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 069/100, Runtime 1.526058, Loss 0.097215, forward nfe 15280, backward nfe 11551, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 070/100, Runtime 1.350696, Loss 0.144917, forward nfe 15512, backward nfe 11661, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 071/100, Runtime 1.676270, Loss 0.129155, forward nfe 15750, backward nfe 11807, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 072/100, Runtime 1.678305, Loss 0.177384, forward nfe 15982, backward nfe 11965, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 073/100, Runtime 1.686012, Loss 0.100249, forward nfe 16208, backward nfe 12133, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 074/100, Runtime 2.092057, Loss 0.158607, forward nfe 16440, backward nfe 12332, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 075/100, Runtime 1.555822, Loss 0.131329, forward nfe 16666, backward nfe 12448, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 076/100, Runtime 1.738913, Loss 0.170044, forward nfe 16892, backward nfe 12607, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 077/100, Runtime 1.199975, Loss 0.231885, forward nfe 17124, backward nfe 12703, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 078/100, Runtime 1.262348, Loss 0.080496, forward nfe 17356, backward nfe 12795, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 079/100, Runtime 1.384603, Loss 0.142540, forward nfe 17588, backward nfe 12920, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 080/100, Runtime 1.722606, Loss 0.169792, forward nfe 17820, backward nfe 13064, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 081/100, Runtime 1.231940, Loss 0.113069, forward nfe 18052, backward nfe 13165, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 082/100, Runtime 1.944367, Loss 0.181244, forward nfe 18284, backward nfe 13353, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 083/100, Runtime 1.762649, Loss 0.162160, forward nfe 18516, backward nfe 13515, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 084/100, Runtime 1.221714, Loss 0.166178, forward nfe 18748, backward nfe 13607, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 085/100, Runtime 1.545508, Loss 0.125596, forward nfe 18980, backward nfe 13745, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 086/100, Runtime 1.437779, Loss 0.110172, forward nfe 19212, backward nfe 13869, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 087/100, Runtime 1.484957, Loss 0.105099, forward nfe 19444, backward nfe 13997, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 088/100, Runtime 2.091229, Loss 0.098735, forward nfe 19682, backward nfe 14200, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 089/100, Runtime 1.877048, Loss 0.143889, forward nfe 19902, backward nfe 14386, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 090/100, Runtime 1.662644, Loss 0.069494, forward nfe 20134, backward nfe 14536, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 091/100, Runtime 1.560087, Loss 0.082259, forward nfe 20366, backward nfe 14674, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 092/100, Runtime 2.237088, Loss 0.146093, forward nfe 20586, backward nfe 14901, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 093/100, Runtime 1.374185, Loss 0.189531, forward nfe 20818, backward nfe 15001, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 094/100, Runtime 2.483397, Loss 0.091180, forward nfe 21038, backward nfe 15206, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 095/100, Runtime 1.300609, Loss 0.080535, forward nfe 21270, backward nfe 15292, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 096/100, Runtime 2.225950, Loss 0.155621, forward nfe 21502, backward nfe 15473, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 097/100, Runtime 2.564063, Loss 0.127623, forward nfe 21728, backward nfe 15712, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 098/100, Runtime 1.808582, Loss 0.154970, forward nfe 21954, backward nfe 15897, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
Epoch: 099/100, Runtime 1.212667, Loss 0.107778, forward nfe 22186, backward nfe 16004, Train: 1.0000, Val: 0.7868, Test: 0.7822, Best time: 128.0000
best val accuracy 0.786806 with test accuracy 0.782181 at epoch 24 and best time 128.000000
[INFO] Loggin into 9_tbl_1_lr_deepgrand_pubmed.json for seed #1...
[INFO] Experiment mode is :  ON
[INFO] ODE function :  ext_laplacian3
[INFO] Block type :  attention
[INFO] T value :  128.0
[INFO] L1 regularization on :  False
[INFO] L1 reg coefficient :  0.001
****************** Extended Laplacian Function V.3 ******************
Clipping Bound =  0.4
Alpha =  3.0
*********************************************************************
****************** Extended Laplacian Function V.3 ******************
Clipping Bound =  0.4
Alpha =  3.0
*********************************************************************
GNNEarly
m1.module.weight
torch.Size([128, 500])
m1.module.bias
torch.Size([128])
m2.module.weight
torch.Size([3, 128])
m2.module.bias
torch.Size([3])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([128, 128])
odeblock.odefunc.d
torch.Size([128])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([128, 128])
odeblock.reg_odefunc.odefunc.d
torch.Size([128])
odeblock.multihead_att_layer.Q.weight
torch.Size([16, 128])
odeblock.multihead_att_layer.Q.bias
torch.Size([16])
odeblock.multihead_att_layer.V.weight
torch.Size([16, 128])
odeblock.multihead_att_layer.V.bias
torch.Size([16])
odeblock.multihead_att_layer.K.weight
torch.Size([16, 128])
odeblock.multihead_att_layer.K.bias
torch.Size([16])
odeblock.multihead_att_layer.Wout.weight
torch.Size([128, 16])
odeblock.multihead_att_layer.Wout.bias
torch.Size([128])
Epoch: 001/100, Runtime 0.577354, Loss 1.100934, forward nfe 38, backward nfe 13, Train: 0.7167, Val: 0.5361, Test: 0.5472, Best time: 22.2651
Epoch: 002/100, Runtime 1.178375, Loss 1.074422, forward nfe 258, backward nfe 104, Train: 0.8167, Val: 0.7292, Test: 0.7233, Best time: 19.9584
Epoch: 003/100, Runtime 1.949391, Loss 1.019812, forward nfe 478, backward nfe 301, Train: 0.8333, Val: 0.7521, Test: 0.7324, Best time: 48.3050
Epoch: 004/100, Runtime 2.209764, Loss 0.948723, forward nfe 698, backward nfe 532, Train: 0.8500, Val: 0.7667, Test: 0.7371, Best time: 74.3524
Epoch: 005/100, Runtime 2.508327, Loss 0.863267, forward nfe 918, backward nfe 777, Train: 0.8500, Val: 0.7667, Test: 0.7371, Best time: 128.0000
Epoch: 006/100, Runtime 2.231537, Loss 0.783933, forward nfe 1138, backward nfe 991, Train: 0.8500, Val: 0.7667, Test: 0.7371, Best time: 128.0000
Epoch: 007/100, Runtime 2.291779, Loss 0.651931, forward nfe 1358, backward nfe 1223, Train: 0.8500, Val: 0.7667, Test: 0.7371, Best time: 128.0000
Epoch: 008/100, Runtime 2.139833, Loss 0.595885, forward nfe 1584, backward nfe 1437, Train: 0.8500, Val: 0.7667, Test: 0.7371, Best time: 128.0000
Epoch: 009/100, Runtime 2.162914, Loss 0.512843, forward nfe 1810, backward nfe 1658, Train: 0.8500, Val: 0.7750, Test: 0.7513, Best time: 76.7326
Epoch: 010/100, Runtime 1.835022, Loss 0.414860, forward nfe 2042, backward nfe 1831, Train: 0.9000, Val: 0.7896, Test: 0.7699, Best time: 78.2268
Epoch: 011/100, Runtime 1.325890, Loss 0.384335, forward nfe 2262, backward nfe 1949, Train: 0.9000, Val: 0.7896, Test: 0.7699, Best time: 128.0000
Epoch: 012/100, Runtime 2.129426, Loss 0.325288, forward nfe 2482, backward nfe 2166, Train: 0.9333, Val: 0.7993, Test: 0.7745, Best time: 67.5770
Epoch: 013/100, Runtime 2.545878, Loss 0.424122, forward nfe 2702, backward nfe 2437, Train: 0.9333, Val: 0.7993, Test: 0.7745, Best time: 128.0000
Epoch: 014/100, Runtime 1.067478, Loss 0.302711, forward nfe 2922, backward nfe 2518, Train: 0.9333, Val: 0.7993, Test: 0.7745, Best time: 128.0000
Epoch: 015/100, Runtime 1.623664, Loss 0.260987, forward nfe 3142, backward nfe 2676, Train: 0.9333, Val: 0.7993, Test: 0.7745, Best time: 128.0000
Epoch: 016/100, Runtime 2.169221, Loss 0.278054, forward nfe 3362, backward nfe 2897, Train: 0.8500, Val: 0.8000, Test: 0.7837, Best time: 460.6438
Epoch: 017/100, Runtime 1.955826, Loss 0.340187, forward nfe 3570, backward nfe 3093, Train: 0.8500, Val: 0.8000, Test: 0.7837, Best time: 128.0000
Epoch: 018/100, Runtime 1.949904, Loss 0.268716, forward nfe 3796, backward nfe 3281, Train: 0.8500, Val: 0.8000, Test: 0.7837, Best time: 128.0000
Epoch: 019/100, Runtime 2.162947, Loss 0.264291, forward nfe 4010, backward nfe 3508, Train: 0.8500, Val: 0.8000, Test: 0.7837, Best time: 128.0000
Epoch: 020/100, Runtime 1.269550, Loss 0.241418, forward nfe 4230, backward nfe 3627, Train: 0.8500, Val: 0.8000, Test: 0.7837, Best time: 128.0000
Epoch: 021/100, Runtime 1.911007, Loss 0.222473, forward nfe 4450, backward nfe 3834, Train: 0.8500, Val: 0.8000, Test: 0.7837, Best time: 128.0000
Epoch: 022/100, Runtime 2.109699, Loss 0.241967, forward nfe 4670, backward nfe 4065, Train: 0.8500, Val: 0.8000, Test: 0.7837, Best time: 128.0000
Epoch: 023/100, Runtime 2.104590, Loss 0.204674, forward nfe 4890, backward nfe 4292, Train: 0.8500, Val: 0.8000, Test: 0.7837, Best time: 128.0000
Epoch: 024/100, Runtime 2.509547, Loss 0.269067, forward nfe 5116, backward nfe 4557, Train: 0.9000, Val: 0.8014, Test: 0.7782, Best time: 360.4839
Epoch: 025/100, Runtime 2.052279, Loss 0.224601, forward nfe 5336, backward nfe 4773, Train: 0.9000, Val: 0.8014, Test: 0.7782, Best time: 128.0000
Epoch: 026/100, Runtime 2.579072, Loss 0.281473, forward nfe 5574, backward nfe 5048, Train: 0.9000, Val: 0.8014, Test: 0.7782, Best time: 128.0000
Epoch: 027/100, Runtime 2.448496, Loss 0.384186, forward nfe 5800, backward nfe 5308, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 482.2412
Epoch: 028/100, Runtime 2.305832, Loss 0.273198, forward nfe 6008, backward nfe 5558, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 029/100, Runtime 2.006859, Loss 0.255426, forward nfe 6240, backward nfe 5756, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 030/100, Runtime 2.111823, Loss 0.196989, forward nfe 6448, backward nfe 5982, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 031/100, Runtime 2.485467, Loss 0.331321, forward nfe 6668, backward nfe 6258, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 032/100, Runtime 2.102893, Loss 0.232666, forward nfe 6876, backward nfe 6484, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 033/100, Runtime 2.370146, Loss 0.208765, forward nfe 7084, backward nfe 6735, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 034/100, Runtime 2.514911, Loss 0.258543, forward nfe 7304, backward nfe 6994, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 035/100, Runtime 2.191014, Loss 0.197778, forward nfe 7530, backward nfe 7231, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 036/100, Runtime 1.327470, Loss 0.198446, forward nfe 7762, backward nfe 7350, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 037/100, Runtime 2.182864, Loss 0.190553, forward nfe 7970, backward nfe 7574, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 038/100, Runtime 2.606405, Loss 0.153854, forward nfe 8184, backward nfe 7836, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 039/100, Runtime 1.994094, Loss 0.179963, forward nfe 8410, backward nfe 8032, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 040/100, Runtime 2.242505, Loss 0.150565, forward nfe 8636, backward nfe 8236, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 041/100, Runtime 1.545721, Loss 0.169615, forward nfe 8862, backward nfe 8369, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 042/100, Runtime 2.530721, Loss 0.195809, forward nfe 9076, backward nfe 8613, Train: 0.9000, Val: 0.8083, Test: 0.7871, Best time: 128.0000
Epoch: 043/100, Runtime 2.317287, Loss 0.148016, forward nfe 9296, backward nfe 8853, Train: 0.9833, Val: 0.8097, Test: 0.7868, Best time: 90.0372
Epoch: 044/100, Runtime 1.898293, Loss 0.184429, forward nfe 9522, backward nfe 9033, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 136.1397
Epoch: 045/100, Runtime 1.869570, Loss 0.135811, forward nfe 9736, backward nfe 9227, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 046/100, Runtime 2.363114, Loss 0.153802, forward nfe 9974, backward nfe 9429, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 047/100, Runtime 1.886612, Loss 0.157792, forward nfe 10200, backward nfe 9620, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 048/100, Runtime 1.309295, Loss 0.178620, forward nfe 10432, backward nfe 9709, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 049/100, Runtime 2.436364, Loss 0.190802, forward nfe 10658, backward nfe 9944, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 050/100, Runtime 1.929929, Loss 0.194327, forward nfe 10890, backward nfe 10084, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 051/100, Runtime 2.210487, Loss 0.224318, forward nfe 11110, backward nfe 10301, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 052/100, Runtime 1.677958, Loss 0.127440, forward nfe 11342, backward nfe 10458, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 053/100, Runtime 2.573745, Loss 0.326000, forward nfe 11574, backward nfe 10737, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 054/100, Runtime 2.052216, Loss 0.265349, forward nfe 11806, backward nfe 10947, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 055/100, Runtime 2.016438, Loss 0.279776, forward nfe 12038, backward nfe 11159, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 056/100, Runtime 2.299831, Loss 0.180946, forward nfe 12258, backward nfe 11411, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 057/100, Runtime 2.170728, Loss 0.201698, forward nfe 12484, backward nfe 11642, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 058/100, Runtime 1.694707, Loss 0.154670, forward nfe 12710, backward nfe 11808, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 059/100, Runtime 1.395375, Loss 0.166989, forward nfe 12942, backward nfe 11931, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 060/100, Runtime 1.825339, Loss 0.180483, forward nfe 13174, backward nfe 12112, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 061/100, Runtime 1.583103, Loss 0.123697, forward nfe 13406, backward nfe 12257, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 062/100, Runtime 1.461414, Loss 0.149852, forward nfe 13638, backward nfe 12393, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 063/100, Runtime 1.185973, Loss 0.142443, forward nfe 13870, backward nfe 12489, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 064/100, Runtime 1.382297, Loss 0.173871, forward nfe 14102, backward nfe 12610, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 065/100, Runtime 2.038566, Loss 0.191898, forward nfe 14334, backward nfe 12821, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 066/100, Runtime 1.676353, Loss 0.157014, forward nfe 14566, backward nfe 12975, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 067/100, Runtime 1.696055, Loss 0.212497, forward nfe 14798, backward nfe 13125, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 068/100, Runtime 2.240792, Loss 0.192245, forward nfe 15030, backward nfe 13351, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 069/100, Runtime 1.983500, Loss 0.182804, forward nfe 15262, backward nfe 13536, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 070/100, Runtime 1.742637, Loss 0.150089, forward nfe 15494, backward nfe 13696, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 071/100, Runtime 1.666068, Loss 0.150517, forward nfe 15726, backward nfe 13828, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 072/100, Runtime 1.598949, Loss 0.237292, forward nfe 15958, backward nfe 13943, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 073/100, Runtime 2.117603, Loss 0.126721, forward nfe 16190, backward nfe 14114, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 074/100, Runtime 3.207928, Loss 0.205586, forward nfe 16416, backward nfe 14409, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 075/100, Runtime 1.914939, Loss 0.185736, forward nfe 16648, backward nfe 14593, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 076/100, Runtime 1.790204, Loss 0.189992, forward nfe 16880, backward nfe 14766, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 077/100, Runtime 1.301338, Loss 0.194774, forward nfe 17112, backward nfe 14873, Train: 0.9667, Val: 0.8104, Test: 0.7881, Best time: 128.0000
Epoch: 078/100, Runtime 2.398592, Loss 0.206462, forward nfe 17338, backward nfe 15113, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 441.2558
Epoch: 079/100, Runtime 1.735367, Loss 0.147186, forward nfe 17570, backward nfe 15267, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 080/100, Runtime 2.147018, Loss 0.214882, forward nfe 17802, backward nfe 15474, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 081/100, Runtime 2.199981, Loss 0.145279, forward nfe 18034, backward nfe 15684, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 082/100, Runtime 1.812181, Loss 0.166381, forward nfe 18266, backward nfe 15851, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 083/100, Runtime 1.905555, Loss 0.156456, forward nfe 18498, backward nfe 16036, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 084/100, Runtime 1.746513, Loss 0.107739, forward nfe 18730, backward nfe 16196, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 085/100, Runtime 2.269561, Loss 0.157010, forward nfe 18956, backward nfe 16443, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 086/100, Runtime 2.388637, Loss 0.096364, forward nfe 19182, backward nfe 16692, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 087/100, Runtime 1.611734, Loss 0.171062, forward nfe 19414, backward nfe 16835, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 088/100, Runtime 1.682828, Loss 0.124648, forward nfe 19646, backward nfe 16977, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 089/100, Runtime 1.877288, Loss 0.141790, forward nfe 19878, backward nfe 17156, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 090/100, Runtime 2.008525, Loss 0.117188, forward nfe 20110, backward nfe 17349, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 091/100, Runtime 1.796760, Loss 0.119384, forward nfe 20348, backward nfe 17531, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 092/100, Runtime 2.004328, Loss 0.110232, forward nfe 20574, backward nfe 17728, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 093/100, Runtime 1.653511, Loss 0.142120, forward nfe 20806, backward nfe 17876, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 094/100, Runtime 1.898786, Loss 0.104957, forward nfe 21038, backward nfe 18050, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 095/100, Runtime 1.662194, Loss 0.122673, forward nfe 21270, backward nfe 18207, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 096/100, Runtime 1.486761, Loss 0.118516, forward nfe 21502, backward nfe 18342, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 097/100, Runtime 1.703317, Loss 0.118199, forward nfe 21734, backward nfe 18511, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 098/100, Runtime 1.177506, Loss 0.189242, forward nfe 21966, backward nfe 18610, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
Epoch: 099/100, Runtime 1.485866, Loss 0.205840, forward nfe 22198, backward nfe 18746, Train: 0.9167, Val: 0.8111, Test: 0.7819, Best time: 128.0000
best val accuracy 0.811111 with test accuracy 0.781907 at epoch 78 and best time 128.000000
[INFO] Loggin into 9_tbl_1_lr_deepgrand_pubmed.json for seed #2...
[INFO] Experiment mode is :  ON
[INFO] ODE function :  ext_laplacian3
[INFO] Block type :  attention
[INFO] T value :  128.0
[INFO] L1 regularization on :  False
[INFO] L1 reg coefficient :  0.001
****************** Extended Laplacian Function V.3 ******************
Clipping Bound =  0.4
Alpha =  3.0
*********************************************************************
****************** Extended Laplacian Function V.3 ******************
Clipping Bound =  0.4
Alpha =  3.0
*********************************************************************
GNNEarly
m1.module.weight
torch.Size([128, 500])
m1.module.bias
torch.Size([128])
m2.module.weight
torch.Size([3, 128])
m2.module.bias
torch.Size([3])
odeblock.odefunc.alpha_train
torch.Size([])
odeblock.odefunc.beta_train
torch.Size([])
odeblock.odefunc.alpha_sc
torch.Size([1])
odeblock.odefunc.beta_sc
torch.Size([1])
odeblock.odefunc.w
torch.Size([128, 128])
odeblock.odefunc.d
torch.Size([128])
odeblock.reg_odefunc.odefunc.alpha_train
torch.Size([])
odeblock.reg_odefunc.odefunc.beta_train
torch.Size([])
odeblock.reg_odefunc.odefunc.alpha_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.beta_sc
torch.Size([1])
odeblock.reg_odefunc.odefunc.w
torch.Size([128, 128])
odeblock.reg_odefunc.odefunc.d
torch.Size([128])
odeblock.multihead_att_layer.Q.weight
torch.Size([16, 128])
odeblock.multihead_att_layer.Q.bias
torch.Size([16])
odeblock.multihead_att_layer.V.weight
torch.Size([16, 128])
odeblock.multihead_att_layer.V.bias
torch.Size([16])
odeblock.multihead_att_layer.K.weight
torch.Size([16, 128])
odeblock.multihead_att_layer.K.bias
torch.Size([16])
odeblock.multihead_att_layer.Wout.weight
torch.Size([128, 16])
odeblock.multihead_att_layer.Wout.bias
torch.Size([128])
Epoch: 001/100, Runtime 0.554646, Loss 1.100949, forward nfe 38, backward nfe 12, Train: 0.4167, Val: 0.4562, Test: 0.4372, Best time: 0.3421
Epoch: 002/100, Runtime 0.621925, Loss 1.101913, forward nfe 258, backward nfe 31, Train: 0.6500, Val: 0.5583, Test: 0.5231, Best time: 29.5028
Epoch: 003/100, Runtime 0.455599, Loss 1.102098, forward nfe 466, backward nfe 54, Train: 0.6500, Val: 0.5583, Test: 0.5231, Best time: 128.0000
Epoch: 004/100, Runtime 0.659342, Loss 1.094100, forward nfe 602, backward nfe 82, Train: 0.6500, Val: 0.5583, Test: 0.5231, Best time: 128.0000
Epoch: 005/100, Runtime 2.352416, Loss 1.082132, forward nfe 804, backward nfe 320, Train: 0.6500, Val: 0.5583, Test: 0.5231, Best time: 128.0000
Epoch: 006/100, Runtime 1.263599, Loss 1.049132, forward nfe 1024, backward nfe 423, Train: 0.9167, Val: 0.7028, Test: 0.6945, Best time: 3.4373
Epoch: 007/100, Runtime 2.285516, Loss 1.004939, forward nfe 1244, backward nfe 656, Train: 0.9167, Val: 0.7597, Test: 0.7488, Best time: 17.2648
Epoch: 008/100, Runtime 2.452629, Loss 0.949463, forward nfe 1464, backward nfe 903, Train: 0.9000, Val: 0.7639, Test: 0.7550, Best time: 43.6790
Epoch: 009/100, Runtime 2.385199, Loss 0.882979, forward nfe 1684, backward nfe 1148, Train: 0.9000, Val: 0.7639, Test: 0.7550, Best time: 128.0000
Epoch: 010/100, Runtime 2.327935, Loss 0.801453, forward nfe 1904, backward nfe 1387, Train: 0.8500, Val: 0.7674, Test: 0.7575, Best time: 43.5712
Epoch: 011/100, Runtime 2.245307, Loss 0.703681, forward nfe 2118, backward nfe 1608, Train: 0.8167, Val: 0.7715, Test: 0.7635, Best time: 80.6543
Epoch: 012/100, Runtime 2.403298, Loss 0.613328, forward nfe 2344, backward nfe 1837, Train: 0.8167, Val: 0.7778, Test: 0.7665, Best time: 116.3787
Epoch: 013/100, Runtime 1.576965, Loss 0.507767, forward nfe 2570, backward nfe 1980, Train: 0.8333, Val: 0.7799, Test: 0.7717, Best time: 83.1720
Epoch: 014/100, Runtime 2.117326, Loss 0.487084, forward nfe 2796, backward nfe 2190, Train: 0.8333, Val: 0.7819, Test: 0.7767, Best time: 154.6942
Epoch: 015/100, Runtime 1.934955, Loss 0.429000, forward nfe 3016, backward nfe 2385, Train: 0.8833, Val: 0.7937, Test: 0.7812, Best time: 115.4408
Epoch: 016/100, Runtime 2.242181, Loss 0.411677, forward nfe 3236, backward nfe 2595, Train: 0.8833, Val: 0.7937, Test: 0.7812, Best time: 128.0000
Epoch: 017/100, Runtime 1.055885, Loss 0.376518, forward nfe 3456, backward nfe 2672, Train: 0.8833, Val: 0.7937, Test: 0.7812, Best time: 128.0000
Epoch: 018/100, Runtime 1.574751, Loss 0.365009, forward nfe 3682, backward nfe 2807, Train: 0.8833, Val: 0.7937, Test: 0.7812, Best time: 128.0000
Epoch: 019/100, Runtime 1.150244, Loss 0.331340, forward nfe 3902, backward nfe 2894, Train: 0.9167, Val: 0.7944, Test: 0.7894, Best time: 237.9504
Epoch: 020/100, Runtime 1.780913, Loss 0.280616, forward nfe 4122, backward nfe 3033, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 493.1023
Epoch: 021/100, Runtime 2.171083, Loss 0.287908, forward nfe 4348, backward nfe 3253, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 022/100, Runtime 2.142658, Loss 0.282659, forward nfe 4562, backward nfe 3471, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 023/100, Runtime 1.345021, Loss 0.243321, forward nfe 4782, backward nfe 3588, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 024/100, Runtime 1.920814, Loss 0.318425, forward nfe 5008, backward nfe 3780, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 025/100, Runtime 1.790326, Loss 0.275859, forward nfe 5228, backward nfe 3954, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 026/100, Runtime 1.946990, Loss 0.310416, forward nfe 5442, backward nfe 4152, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 027/100, Runtime 2.187401, Loss 0.271793, forward nfe 5650, backward nfe 4378, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 028/100, Runtime 2.370520, Loss 0.275848, forward nfe 5864, backward nfe 4617, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 029/100, Runtime 2.283579, Loss 0.296683, forward nfe 6072, backward nfe 4858, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 030/100, Runtime 2.056113, Loss 0.254257, forward nfe 6280, backward nfe 5066, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 031/100, Runtime 2.331154, Loss 0.242565, forward nfe 6488, backward nfe 5307, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 032/100, Runtime 2.414740, Loss 0.178414, forward nfe 6696, backward nfe 5544, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 033/100, Runtime 2.491718, Loss 0.201212, forward nfe 6910, backward nfe 5791, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 034/100, Runtime 2.029781, Loss 0.251834, forward nfe 7118, backward nfe 5993, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 035/100, Runtime 2.098096, Loss 0.292175, forward nfe 7326, backward nfe 6193, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 036/100, Runtime 2.035825, Loss 0.197845, forward nfe 7540, backward nfe 6402, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 037/100, Runtime 2.402937, Loss 0.182666, forward nfe 7754, backward nfe 6653, Train: 0.8333, Val: 0.8083, Test: 0.7954, Best time: 128.0000
Epoch: 038/100, Runtime 1.942340, Loss 0.313509, forward nfe 7962, backward nfe 6846, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 329.6603
Epoch: 039/100, Runtime 2.285196, Loss 0.184586, forward nfe 8170, backward nfe 7077, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 040/100, Runtime 1.985275, Loss 0.149252, forward nfe 8396, backward nfe 7272, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 041/100, Runtime 1.716095, Loss 0.307424, forward nfe 8616, backward nfe 7448, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 042/100, Runtime 2.030528, Loss 0.201886, forward nfe 8824, backward nfe 7669, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 043/100, Runtime 1.729123, Loss 0.148695, forward nfe 9056, backward nfe 7846, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 044/100, Runtime 1.997622, Loss 0.298533, forward nfe 9276, backward nfe 8057, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 045/100, Runtime 1.970634, Loss 0.198964, forward nfe 9490, backward nfe 8259, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 046/100, Runtime 2.142491, Loss 0.183470, forward nfe 9692, backward nfe 8485, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 047/100, Runtime 1.874402, Loss 0.154886, forward nfe 9900, backward nfe 8671, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 048/100, Runtime 1.144009, Loss 0.175859, forward nfe 10132, backward nfe 8762, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 049/100, Runtime 2.226551, Loss 0.153021, forward nfe 10358, backward nfe 8995, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 050/100, Runtime 2.038639, Loss 0.201882, forward nfe 10578, backward nfe 9203, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 051/100, Runtime 1.120746, Loss 0.213064, forward nfe 10798, backward nfe 9288, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 052/100, Runtime 1.319137, Loss 0.158201, forward nfe 11024, backward nfe 9400, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 053/100, Runtime 1.412677, Loss 0.240797, forward nfe 11256, backward nfe 9524, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 054/100, Runtime 1.311733, Loss 0.153109, forward nfe 11482, backward nfe 9632, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 055/100, Runtime 1.335546, Loss 0.201423, forward nfe 11702, backward nfe 9741, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 056/100, Runtime 1.277528, Loss 0.148088, forward nfe 11934, backward nfe 9846, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 057/100, Runtime 1.937885, Loss 0.205314, forward nfe 12148, backward nfe 10038, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 058/100, Runtime 1.742076, Loss 0.213693, forward nfe 12380, backward nfe 10189, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 059/100, Runtime 2.622466, Loss 0.213509, forward nfe 12594, backward nfe 10464, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 060/100, Runtime 1.371332, Loss 0.186958, forward nfe 12826, backward nfe 10561, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 061/100, Runtime 1.500164, Loss 0.218193, forward nfe 13058, backward nfe 10688, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 062/100, Runtime 1.789386, Loss 0.124591, forward nfe 13284, backward nfe 10858, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 063/100, Runtime 1.926380, Loss 0.168334, forward nfe 13510, backward nfe 11040, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 064/100, Runtime 1.286100, Loss 0.145954, forward nfe 13736, backward nfe 11128, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 065/100, Runtime 1.536172, Loss 0.165421, forward nfe 13962, backward nfe 11262, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 066/100, Runtime 2.203066, Loss 0.174592, forward nfe 14182, backward nfe 11487, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 067/100, Runtime 1.762810, Loss 0.149591, forward nfe 14414, backward nfe 11646, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 068/100, Runtime 1.790630, Loss 0.184064, forward nfe 14646, backward nfe 11791, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 069/100, Runtime 1.892197, Loss 0.170197, forward nfe 14878, backward nfe 11962, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 070/100, Runtime 1.233305, Loss 0.160392, forward nfe 15104, backward nfe 12049, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 071/100, Runtime 1.256012, Loss 0.167215, forward nfe 15330, backward nfe 12148, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 072/100, Runtime 1.520527, Loss 0.122326, forward nfe 15556, backward nfe 12267, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 073/100, Runtime 1.252975, Loss 0.142824, forward nfe 15770, backward nfe 12362, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 074/100, Runtime 2.301762, Loss 0.165478, forward nfe 16008, backward nfe 12549, Train: 0.9500, Val: 0.8153, Test: 0.7992, Best time: 128.0000
Epoch: 075/100, Runtime 2.102849, Loss 0.146615, forward nfe 16228, backward nfe 12758, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 510.5056
Epoch: 076/100, Runtime 1.540231, Loss 0.133331, forward nfe 16454, backward nfe 12890, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 077/100, Runtime 1.663320, Loss 0.112771, forward nfe 16680, backward nfe 13047, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 078/100, Runtime 2.490642, Loss 0.104257, forward nfe 16888, backward nfe 13303, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 079/100, Runtime 2.058902, Loss 0.159340, forward nfe 17114, backward nfe 13480, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 080/100, Runtime 1.569272, Loss 0.128853, forward nfe 17346, backward nfe 13626, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 081/100, Runtime 1.968538, Loss 0.170532, forward nfe 17566, backward nfe 13816, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 082/100, Runtime 2.249753, Loss 0.116879, forward nfe 17780, backward nfe 14034, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 083/100, Runtime 1.998974, Loss 0.126642, forward nfe 18012, backward nfe 14230, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 084/100, Runtime 1.833595, Loss 0.131895, forward nfe 18232, backward nfe 14395, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 085/100, Runtime 1.597727, Loss 0.203772, forward nfe 18458, backward nfe 14542, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 086/100, Runtime 2.642891, Loss 0.139443, forward nfe 18678, backward nfe 14753, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 087/100, Runtime 1.599517, Loss 0.125629, forward nfe 18910, backward nfe 14874, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 088/100, Runtime 1.401437, Loss 0.117700, forward nfe 19142, backward nfe 14954, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 089/100, Runtime 2.109025, Loss 0.100888, forward nfe 19362, backward nfe 15132, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 090/100, Runtime 1.603042, Loss 0.106961, forward nfe 19582, backward nfe 15292, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 091/100, Runtime 2.123483, Loss 0.127592, forward nfe 19796, backward nfe 15499, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 092/100, Runtime 1.971396, Loss 0.172478, forward nfe 20028, backward nfe 15657, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 093/100, Runtime 1.382922, Loss 0.165829, forward nfe 20260, backward nfe 15765, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 094/100, Runtime 2.665493, Loss 0.157162, forward nfe 20480, backward nfe 15969, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 095/100, Runtime 1.944057, Loss 0.186552, forward nfe 20712, backward nfe 16099, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 096/100, Runtime 1.741237, Loss 0.140992, forward nfe 20944, backward nfe 16261, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 097/100, Runtime 2.147810, Loss 0.115198, forward nfe 21164, backward nfe 16470, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 098/100, Runtime 1.360353, Loss 0.125519, forward nfe 21390, backward nfe 16575, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
Epoch: 099/100, Runtime 1.789119, Loss 0.114902, forward nfe 21622, backward nfe 16729, Train: 0.9667, Val: 0.8167, Test: 0.8010, Best time: 128.0000
best val accuracy 0.816667 with test accuracy 0.800955 at epoch 75 and best time 128.000000
[INFO] Loggin into 9_tbl_1_lr_deepgrand_pubmed.json for seed #3...
[INFO] Experiment mode is :  ON
[INFO] ODE function :  ext_laplacian3
[INFO] Block type :  attention
[INFO] T value :  128.0
[INFO] L1 regularization on :  False
[INFO] L1 reg coefficient :  0.001
Traceback (most recent call last):
  File "test_multiple_planetoid_splits.py", line 388, in <module>
    fw_nfes, losses, train_accs, val_accs, test_accs = main(opt)
  File "/home/administrator/hieu/graph-neural-pde/src/run_GNN.py", line 213, in main
    dataset = get_dataset(opt, '../data', opt['not_lcc'])
  File "/home/administrator/hieu/graph-neural-pde/src/data.py", line 63, in get_dataset
    edges = [[i, j] for i, j in zip(row, col) if i in lcc and j in lcc]
  File "/home/administrator/hieu/graph-neural-pde/src/data.py", line 63, in <listcomp>
    edges = [[i, j] for i, j in zip(row, col) if i in lcc and j in lcc]
KeyboardInterrupt